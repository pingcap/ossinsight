"use strict";(self.webpackChunkweb=self.webpackChunkweb||[]).push([[1477],{30010:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/how-to-build-oss-comparison-gpt","metadata":{"permalink":"/blog/how-to-build-oss-comparison-gpt","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/how-to-build-oss-comparison-gpt/index.mdx","source":"@site/blog/how-to-build-oss-comparison-gpt/index.mdx","title":"Configurations for building \\"Open Source Benchmark\\" GPTs","description":"This blog contains all the configurations while building OSS Comparison GPTs.","date":"2023-12-11T00:00:00.000Z","formattedDate":"December 11, 2023","tags":[{"label":"openai","permalink":"/blog/tags/openai"},{"label":"chatgpt","permalink":"/blog/tags/chatgpt"},{"label":"gpts","permalink":"/blog/tags/gpts"}],"readingTime":17.155,"hasTruncateMarker":false,"authors":[{"name":"sykp241095","title":"Contributor of TiDB Community","url":"https://twitter.com/sykp241095","imageURL":"https://github.com/sykp241095.png","key":"sykp241095"},{"name":"ChatGPT","title":"Robot from OpenAI","url":"https://chat.openai.com/","imageURL":"https://github.com/openai.png","key":"chatgpt"}],"frontMatter":{"title":"Configurations for building \\"Open Source Benchmark\\" GPTs","description":"This blog contains all the configurations while building OSS Comparison GPTs.","date":"2023-12-11T00:00:00.000Z","authors":["sykp241095","chatgpt"],"tags":["openai","chatgpt","gpts"]},"nextItem":{"title":"How to Learn SQL Easily by Visualizing with ChatGPT","permalink":"/blog/how-to-learn-sql-easily-by-visualizing-with-chatgpt"}},"content":"In this blog, we will share every configurations to build a OSS Comparison GPT.\\n\\n## GPTs Configurations\\n\\n### Name\\n```\\nOpen Source Benchmark\\n```\\n\\n### Description\\n```\\nCompare open-source softwares\\n```\\n\\n### Instructions\\n```\\nYou are a data analysis expert. \\nWhen a user inputs one or more  open-source software/technology terms, you provide a comprehensive comparison of their data, \\nsuch as popularity, GitHub stars count, contributors count, user geographical distribution, stargazers company distribution,  Hacker News keyword mention counts, \\nlong-term trend data, and more. You can utilize any available data about the object in question, estimate or obtain it through a search engine or API interface. \\nCurrently, you have the following APIs at your disposal:\\n\\n1. GitHub API for getting repo basic info\\n2. OSS Insight API for star history and stargazer\'s distribution\\n3. Hackernews mentions per_year API\\n4. OSS Insight star history chart API (show me with a <img> label)\\n5. OSS Insight API for  stargazers company distribution\\n\\nHere\'s a step-by-step process:\\n\\nIdentify which API to use based on the data you need.\\n- you goal is to think more metrics according exist API.\\n- each step you output your thought\\n- your action\\n- at least 8 metrics you should give\\nOutput the data in a markdown table for easy comparison. add your known metrics for more insight. at least 8 metrics.\\n\\n| Dimension      | A           | B           |\\n|----------------|-------------|-------------|\\n| Dimension 1    | Detail A1   | Detail B1   |\\n| Dimension 2    | Detail A2   | Detail B2   |\\n| Dimension 3    | Detail A3   | Detail B3   |\\n| ...            | ...         | ...         |\\n| Dimension N    | Detail AN   | Detail BN   |\\n\\n- For star history data, you should generate a line chart using oss insight star history api, at least one chart.\\n- For stargazers company data, you use markdown table:\\n| Company         | Stargazers Count |\\n|-----------------|------------------|\\n| Company A       | 100              |\\n| Company B       | 75               |\\n| Company C       | 50               |\\n| Company D       | 30               |\\n| Other/Unknown   | 45               |\\n\\nProvide insights and analysis based on the collected data. and trending insight.\\nBe sure to think big! Always give plan and explain what you do.\\n\\nLet\'s begin\\n\\nPlan:\\nTools:\\nAction:\\nOutput:\\nDeep Insight:\\n\\nAt the end, you should give use some surprise, you can search stackshare.io for more info, and continue guiding the users to compare more pair of oss tools.\\n```\\n\\n### Conversation starters\\n```\\nPyTorch vs TensorFlow\\nTiDB vs Vitess\\nReact vs Vue\\nGolang vs Rust-lang\\n```\\n\\n### Capabilities\\n\\n:::tip\\nMake all these three capabilities checked\\n:::\\n\\n* [x] Web Browsing\\n* [x] DALL-E Image Generation\\n* [x] Code Interpreter\\n\\n### Actions\\n\\n#### Action 1: Config API of next.ossinsight.io for drawing star historical chart\\n\\n##### Schema\\n```yaml\\nopenapi: 3.0.0\\ninfo:\\n  title: OSS Insight star history chart API\\n  version: 1.0.0\\n  description: OSS Insight star history chart API.\\nservers:\\n  - url: https://next.ossinsight.io\\npaths:\\n  /widgets/official/analyze-repo-stars-history/manifest.json:\\n    get:\\n      operationId: Star History\\n      summary: Retrieve repository star history analysis\\n      description: Fetches the star history and analysis for specified repositories.\\n      parameters:\\n        - name: repo_id\\n          in: query\\n          required: true\\n          description: The ID of the primary repository.\\n          schema:\\n            type: integer\\n        - name: vs_repo_id\\n          in: query\\n          required: true\\n          description: The ID of the repository to compare with.\\n          schema:\\n            type: integer\\n      responses:\\n        \'200\':\\n          description: Successful response with star history data.\\n          content:\\n            application/json:\\n              schema:\\n                type: object\\n                properties:\\n                  imageUrl:\\n                    type: string\\n                    format: uri\\n                    description: URL of the thumbnail image.\\n                  title:\\n                    type: string\\n                    description: Title of the analysis.\\n                  description:\\n                    type: string\\n                    description: Description of the analysis.\\n        \'400\':\\n          description: Bad request - parameters missing or invalid.\\n        \'404\':\\n          description: Resource not found.\\n        \'500\':\\n          description: Internal server error.\\n```\\n\\n##### Privacy policy\\n\\n```\\nhttps://www.pingcap.com/privacy-policy/\\n```\\n\\n#### Action 2: Config api.github.com for fetching basic info of a repository\\n\\nAs GitHub API use `Personal Access Token` and `Bearer` type of authentication for authentication, you should create one in: https://github.com/settings/tokens, it will be used later.\\n\\n##### Schema:\\n\\n```\\nopenapi: 3.0.0\\ninfo:\\n  title: GitHub Repository Info API\\n  description: An API for retrieving information about GitHub repositories.\\n  version: 1.0.0\\nservers:\\n  - url: https://api.github.com\\n    description: GitHub API Server\\npaths:\\n  /repos/{owner}/{repo}:\\n    get:\\n      summary: Get Repository Info\\n      description: Retrieve information about a GitHub repository.\\n      operationId: getRepositoryInfo\\n      parameters:\\n        - name: owner\\n          in: path\\n          required: true\\n          schema:\\n            type: string\\n          description: The username or organization name of the repository owner.\\n        - name: repo\\n          in: path\\n          required: true\\n          schema:\\n            type: string\\n          description: The name of the repository.\\n      responses:\\n        \'200\':\\n          description: Successful response with repository information.\\n          content:\\n            application/json:\\n              schema:\\n                type: object\\n                properties:\\n                  id:\\n                    type: integer\\n                  name:\\n                    type: string\\n                  full_name:\\n                    type: string\\n                  owner:\\n                    type: object\\n                    properties:\\n                      login:\\n                        type: string\\n                      id:\\n                        type: integer\\n                      avatar_url:\\n                        type: string\\n                      html_url:\\n                        type: string\\n                  private:\\n                    type: boolean\\n                  description:\\n                    type: string\\n                  fork:\\n                    type: boolean\\n                  url:\\n                    type: string\\n                  html_url:\\n                    type: string\\n                  language:\\n                    type: string\\n                  forks_count:\\n                    type: integer\\n                  stargazers_count:\\n                    type: integer\\n                  watchers_count:\\n                    type: integer\\n                  size:\\n                    type: integer\\n                  default_branch:\\n                    type: string\\n                  open_issues_count:\\n                    type: integer\\n                  topics:\\n                    type: array\\n                    items:\\n                      type: string\\n                  has_issues:\\n                    type: boolean\\n                  has_projects:\\n                    type: boolean\\n                  has_wiki:\\n                    type: boolean\\n                  has_pages:\\n                    type: boolean\\n                  has_downloads:\\n                    type: boolean\\n                  has_discussions:\\n                    type: boolean\\n                  archived:\\n                    type: boolean\\n                  disabled:\\n                    type: boolean\\n                  visibility:\\n                    type: string\\n                  pushed_at:\\n                    type: string\\n                    format: date-time\\n                  created_at:\\n                    type: string\\n                    format: date-time\\n                  updated_at:\\n                    type: string\\n                    format: date-time\\n                  license:\\n                    type: object\\n                    properties:\\n                      key:\\n                        type: string\\n                      name:\\n                        type: string\\n                      spdx_id:\\n                        type: string\\n                      url:\\n                        type: string\\n```\\n\\n##### Privacy policy\\n\\n```\\nhttps://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement\\n```\\n\\n\\n#### Action 3: Stargazer\'s geo & company distribution provided by TiDB Serverless Data Service\\n\\n##### Schema URL to import\\n\\n\\n```\\nhttps://us-west-2.prod.aws.tidbcloud.com/api/v1/dataservices/external/appexport/openapi?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBpZCI6ImRhdGFhcHAtUmZGS2NaRnUiLCJjcmVhdGVyIjoiaHVvaGFvQHBpbmdjYXAuY29tIiwic2VuY2UiOiJvcGVuYXBpIn0.xqu-ZCPHozisIHWTD5XM_5t2JWOGVpAejcQeWiTH_Mw\\n```\\n\\n\\nor you can use the following details schema.\\n<details><summary>Show detailed API schema</summary>\\n<p>\\n\\n```json\\ncomponents:\\n  schemas:\\n    getGithubRepoStar_historyResponse:\\n      properties:\\n        data:\\n          properties:\\n            columns:\\n              items:\\n                properties:\\n                  col:\\n                    type: string\\n                  data_type:\\n                    type: string\\n                  nullable:\\n                    type: boolean\\n                type: object\\n              type: array\\n            result:\\n              properties:\\n                code:\\n                  format: int64\\n                  type: integer\\n                end_ms:\\n                  format: int64\\n                  type: integer\\n                latency:\\n                  type: string\\n                limit:\\n                  maximum: 1.8446744073709552e+19\\n                  minimum: 0\\n                  type: integer\\n                message:\\n                  type: string\\n                row_affect:\\n                  format: int64\\n                  type: integer\\n                row_count:\\n                  format: int64\\n                  type: integer\\n                start_ms:\\n                  format: int64\\n                  type: integer\\n                warn_count:\\n                  type: integer\\n                warn_messages:\\n                  items:\\n                    type: string\\n                  type: array\\n              type: object\\n            rows:\\n              items:\\n                properties:\\n                  date:\\n                    type: string\\n                  stargazers:\\n                    type: string\\n                required:\\n                - date\\n                - stargazers\\n                type: object\\n              type: array\\n          required:\\n          - columns\\n          - rows\\n          - result\\n          type: object\\n        type:\\n          type: string\\n      required:\\n      - type\\n      - data\\n      type: object\\n    getGithubRepoStargazers_companyResponse:\\n      properties:\\n        data:\\n          properties:\\n            columns:\\n              items:\\n                properties:\\n                  col:\\n                    type: string\\n                  data_type:\\n                    type: string\\n                  nullable:\\n                    type: boolean\\n                type: object\\n              type: array\\n            result:\\n              properties:\\n                code:\\n                  format: int64\\n                  type: integer\\n                end_ms:\\n                  format: int64\\n                  type: integer\\n                latency:\\n                  type: string\\n                limit:\\n                  maximum: 1.8446744073709552e+19\\n                  minimum: 0\\n                  type: integer\\n                message:\\n                  type: string\\n                row_affect:\\n                  format: int64\\n                  type: integer\\n                row_count:\\n                  format: int64\\n                  type: integer\\n                start_ms:\\n                  format: int64\\n                  type: integer\\n                warn_count:\\n                  type: integer\\n                warn_messages:\\n                  items:\\n                    type: string\\n                  type: array\\n              type: object\\n            rows:\\n              items:\\n                properties:\\n                  company_name:\\n                    type: string\\n                  proportion:\\n                    type: string\\n                  stargazers:\\n                    type: string\\n                required:\\n                - company_name\\n                - stargazers\\n                - proportion\\n                type: object\\n              type: array\\n          required:\\n          - columns\\n          - rows\\n          - result\\n          type: object\\n        type:\\n          type: string\\n      required:\\n      - type\\n      - data\\n      type: object\\n    getGithubRepoStargazers_countryResponse:\\n      properties:\\n        data:\\n          properties:\\n            columns:\\n              items:\\n                properties:\\n                  col:\\n                    type: string\\n                  data_type:\\n                    type: string\\n                  nullable:\\n                    type: boolean\\n                type: object\\n              type: array\\n            result:\\n              properties:\\n                code:\\n                  format: int64\\n                  type: integer\\n                end_ms:\\n                  format: int64\\n                  type: integer\\n                latency:\\n                  type: string\\n                limit:\\n                  maximum: 1.8446744073709552e+19\\n                  minimum: 0\\n                  type: integer\\n                message:\\n                  type: string\\n                row_affect:\\n                  format: int64\\n                  type: integer\\n                row_count:\\n                  format: int64\\n                  type: integer\\n                start_ms:\\n                  format: int64\\n                  type: integer\\n                warn_count:\\n                  type: integer\\n                warn_messages:\\n                  items:\\n                    type: string\\n                  type: array\\n              type: object\\n            rows:\\n              items:\\n                properties:\\n                  country_code:\\n                    type: string\\n                  percentage:\\n                    type: string\\n                  stargazers:\\n                    type: string\\n                required:\\n                - country_code\\n                - stargazers\\n                - percentage\\n                type: object\\n              type: array\\n          required:\\n          - columns\\n          - rows\\n          - result\\n          type: object\\n        type:\\n          type: string\\n      required:\\n      - type\\n      - data\\n      type: object\\n    getHackernewsMentions_countResponse:\\n      properties:\\n        data:\\n          properties:\\n            columns:\\n              items:\\n                properties:\\n                  col:\\n                    type: string\\n                  data_type:\\n                    type: string\\n                  nullable:\\n                    type: boolean\\n                type: object\\n              type: array\\n            result:\\n              properties:\\n                code:\\n                  format: int64\\n                  type: integer\\n                end_ms:\\n                  format: int64\\n                  type: integer\\n                latency:\\n                  type: string\\n                limit:\\n                  maximum: 1.8446744073709552e+19\\n                  minimum: 0\\n                  type: integer\\n                message:\\n                  type: string\\n                row_affect:\\n                  format: int64\\n                  type: integer\\n                row_count:\\n                  format: int64\\n                  type: integer\\n                start_ms:\\n                  format: int64\\n                  type: integer\\n                warn_count:\\n                  type: integer\\n                warn_messages:\\n                  items:\\n                    type: string\\n                  type: array\\n              type: object\\n            rows:\\n              items:\\n                properties:\\n                  count:\\n                    type: string\\n                required:\\n                - count\\n                type: object\\n              type: array\\n          required:\\n          - columns\\n          - rows\\n          - result\\n          type: object\\n        type:\\n          type: string\\n      required:\\n      - type\\n      - data\\n      type: object\\n    getHackernewsMentions_per_yearResponse:\\n      properties:\\n        data:\\n          properties:\\n            columns:\\n              items:\\n                properties:\\n                  col:\\n                    type: string\\n                  data_type:\\n                    type: string\\n                  nullable:\\n                    type: boolean\\n                type: object\\n              type: array\\n            result:\\n              properties:\\n                code:\\n                  format: int64\\n                  type: integer\\n                end_ms:\\n                  format: int64\\n                  type: integer\\n                latency:\\n                  type: string\\n                limit:\\n                  maximum: 1.8446744073709552e+19\\n                  minimum: 0\\n                  type: integer\\n                message:\\n                  type: string\\n                row_affect:\\n                  format: int64\\n                  type: integer\\n                row_count:\\n                  format: int64\\n                  type: integer\\n                start_ms:\\n                  format: int64\\n                  type: integer\\n                warn_count:\\n                  type: integer\\n                warn_messages:\\n                  items:\\n                    type: string\\n                  type: array\\n              type: object\\n            rows:\\n              items:\\n                properties:\\n                  count:\\n                    type: string\\n                  date:\\n                    type: string\\n                required:\\n                - count\\n                - date\\n                type: object\\n              type: array\\n          required:\\n          - columns\\n          - rows\\n          - result\\n          type: object\\n        type:\\n          type: string\\n      required:\\n      - type\\n      - data\\n      type: object\\n  securitySchemes:\\n    basicAuth:\\n      description: Enter your public key for the username field and private key for\\n        the password field\\n      scheme: basic\\n      type: http\\ninfo:\\n  description: API Interface for GPT PK Action, response GitHub repo metrics and hackernews\\n    mentions count data\\n  title: GPT-PK\\n  version: 1.0.0\\nopenapi: 3.0.3\\npaths:\\n  /github/repo/star_history:\\n    get:\\n      description: GitHub repo star history\\n      operationId: getGithubRepoStar_history\\n      parameters:\\n      - description: The time interval of the data points\\n        in: query\\n        name: per\\n        schema:\\n          default: month\\n          enum:\\n          - day\\n          - week\\n          - month\\n          example: month\\n          type: string\\n      - description: \'The owner of the repo. For example: `pingcap`\'\\n        in: query\\n        name: owner\\n        required: true\\n        schema:\\n          default: \\"\\"\\n          example: \\"\\"\\n          type: string\\n      - description: \'The name of the repo. For example: `tidb`\'\\n        in: query\\n        name: repo\\n        required: true\\n        schema:\\n          default: \\"\\"\\n          example: \\"\\"\\n          type: string\\n      - description: The start date of the range\\n        in: query\\n        name: from\\n        schema:\\n          default: \\"2000-01-01\\"\\n          example: \\"2000-01-01\\"\\n          type: string\\n      - description: The end date of the range\\n        in: query\\n        name: to\\n        schema:\\n          default: \\"2099-12-31\\"\\n          example: \\"2099-12-31\\"\\n          type: string\\n      responses:\\n        \\"200\\":\\n          content:\\n            application/json:\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStar_historyResponse\'\\n          description: OK\\n        \\"400\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 400\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: param check failed! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStar_historyResponse\'\\n          description: Bad request\\n        \\"401\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 401\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: auth failed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStar_historyResponse\'\\n          description: Unauthorized request\\n        \\"404\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 404\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: endpoint not found\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStar_historyResponse\'\\n          description: The requested resource was not found\\n        \\"405\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 405\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: method not allowed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStar_historyResponse\'\\n          description: The requested method is not supported for the specified resource\\n        \\"408\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 408\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: request timeout\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStar_historyResponse\'\\n          description: The server timed out waiting for the request\\n        \\"429\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 429\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: \'The request exceeded the limit of 100 times per apikey\\n                      per minute. For more quota, please contact us: https://support.pingcap.com/hc/en-us/requests/new?ticket_form_id=7800003722519\'\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStar_historyResponse\'\\n          description: The user has sent too many requests in a given amount of time\\n        \\"500\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 500\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: internal error! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStar_historyResponse\'\\n          description: Internal server error\\n      summary: /github/repo/star_history\\n      tags:\\n      - Default\\n  /github/repo/stargazers_company:\\n    get:\\n      operationId: getGithubRepoStargazers_company\\n      parameters:\\n      - in: query\\n        name: owner\\n        schema:\\n          default: \\"\\"\\n          example: \\"\\"\\n          type: string\\n      - in: query\\n        name: repo\\n        schema:\\n          default: \\"\\"\\n          example: \\"\\"\\n          type: string\\n      - in: query\\n        name: from\\n        schema:\\n          default: \\"2000-01-01\\"\\n          example: \\"2000-01-01\\"\\n          type: string\\n      - in: query\\n        name: to\\n        schema:\\n          default: \\"2099-01-01\\"\\n          example: \\"2099-01-01\\"\\n          type: string\\n      responses:\\n        \\"200\\":\\n          content:\\n            application/json:\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_companyResponse\'\\n          description: OK\\n        \\"400\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 400\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: param check failed! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_companyResponse\'\\n          description: Bad request\\n        \\"401\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 401\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: auth failed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_companyResponse\'\\n          description: Unauthorized request\\n        \\"404\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 404\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: endpoint not found\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_companyResponse\'\\n          description: The requested resource was not found\\n        \\"405\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 405\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: method not allowed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_companyResponse\'\\n          description: The requested method is not supported for the specified resource\\n        \\"408\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 408\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: request timeout\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_companyResponse\'\\n          description: The server timed out waiting for the request\\n        \\"429\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 429\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: \'The request exceeded the limit of 100 times per apikey\\n                      per minute. For more quota, please contact us: https://support.pingcap.com/hc/en-us/requests/new?ticket_form_id=7800003722519\'\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_companyResponse\'\\n          description: The user has sent too many requests in a given amount of time\\n        \\"500\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 500\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: internal error! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_companyResponse\'\\n          description: Internal server error\\n      summary: /github/repo/stargazers_company\\n      tags:\\n      - Default\\n  /github/repo/stargazers_country:\\n    get:\\n      description: github repo stargazers country\\n      operationId: getGithubRepoStargazers_country\\n      parameters:\\n      - in: query\\n        name: owner\\n        schema:\\n          default: \\"\\"\\n          example: \\"\\"\\n          type: string\\n      - in: query\\n        name: repo\\n        schema:\\n          default: \\"\\"\\n          example: \\"\\"\\n          type: string\\n      - in: query\\n        name: from\\n        schema:\\n          default: \\"2000-01-01\\"\\n          example: \\"2000-01-01\\"\\n          type: string\\n      - in: query\\n        name: to\\n        schema:\\n          default: \\"2099-01-01\\"\\n          example: \\"2099-01-01\\"\\n          type: string\\n      - in: query\\n        name: exclude_unknown\\n        schema:\\n          default: \\"true\\"\\n          example: \\"true\\"\\n          type: boolean\\n      responses:\\n        \\"200\\":\\n          content:\\n            application/json:\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_countryResponse\'\\n          description: OK\\n        \\"400\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 400\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: param check failed! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_countryResponse\'\\n          description: Bad request\\n        \\"401\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 401\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: auth failed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_countryResponse\'\\n          description: Unauthorized request\\n        \\"404\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 404\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: endpoint not found\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_countryResponse\'\\n          description: The requested resource was not found\\n        \\"405\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 405\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: method not allowed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_countryResponse\'\\n          description: The requested method is not supported for the specified resource\\n        \\"408\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 408\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: request timeout\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_countryResponse\'\\n          description: The server timed out waiting for the request\\n        \\"429\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 429\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: \'The request exceeded the limit of 100 times per apikey\\n                      per minute. For more quota, please contact us: https://support.pingcap.com/hc/en-us/requests/new?ticket_form_id=7800003722519\'\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_countryResponse\'\\n          description: The user has sent too many requests in a given amount of time\\n        \\"500\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 500\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: internal error! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getGithubRepoStargazers_countryResponse\'\\n          description: Internal server error\\n      summary: /github/repo/stargazers_country\\n      tags:\\n      - Default\\n  /hackernews/mentions_count:\\n    get:\\n      description: Total counts for keyword in hackernews\\n      operationId: getHackernewsMentions_count\\n      parameters:\\n      - in: query\\n        name: keyword\\n        schema:\\n          default: \\"\\"\\n          example: \\"\\"\\n          type: string\\n      responses:\\n        \\"200\\":\\n          content:\\n            application/json:\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_countResponse\'\\n          description: OK\\n        \\"400\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 400\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: param check failed! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_countResponse\'\\n          description: Bad request\\n        \\"401\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 401\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: auth failed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_countResponse\'\\n          description: Unauthorized request\\n        \\"404\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 404\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: endpoint not found\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_countResponse\'\\n          description: The requested resource was not found\\n        \\"405\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 405\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: method not allowed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_countResponse\'\\n          description: The requested method is not supported for the specified resource\\n        \\"408\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 408\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: request timeout\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_countResponse\'\\n          description: The server timed out waiting for the request\\n        \\"429\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 429\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: \'The request exceeded the limit of 100 times per apikey\\n                      per minute. For more quota, please contact us: https://support.pingcap.com/hc/en-us/requests/new?ticket_form_id=7800003722519\'\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_countResponse\'\\n          description: The user has sent too many requests in a given amount of time\\n        \\"500\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 500\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: internal error! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_countResponse\'\\n          description: Internal server error\\n      summary: /hackernews/mentions_count\\n      tags:\\n      - Default\\n  /hackernews/mentions_per_year:\\n    get:\\n      description: keyword mentions per year in hackernews\\n      operationId: getHackernewsMentions_per_year\\n      parameters:\\n      - in: query\\n        name: keyword\\n        schema:\\n          default: \\"\\"\\n          example: \\"\\"\\n          type: string\\n      responses:\\n        \\"200\\":\\n          content:\\n            application/json:\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_per_yearResponse\'\\n          description: OK\\n        \\"400\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 400\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: param check failed! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_per_yearResponse\'\\n          description: Bad request\\n        \\"401\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 401\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: auth failed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_per_yearResponse\'\\n          description: Unauthorized request\\n        \\"404\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 404\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: endpoint not found\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_per_yearResponse\'\\n          description: The requested resource was not found\\n        \\"405\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 405\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: method not allowed\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_per_yearResponse\'\\n          description: The requested method is not supported for the specified resource\\n        \\"408\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 408\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: request timeout\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_per_yearResponse\'\\n          description: The server timed out waiting for the request\\n        \\"429\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 429\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: \'The request exceeded the limit of 100 times per apikey\\n                      per minute. For more quota, please contact us: https://support.pingcap.com/hc/en-us/requests/new?ticket_form_id=7800003722519\'\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_per_yearResponse\'\\n          description: The user has sent too many requests in a given amount of time\\n        \\"500\\":\\n          content:\\n            application/json:\\n              example:\\n                data:\\n                  columns: []\\n                  result:\\n                    code: 500\\n                    end_ms: 0\\n                    latency: \\"\\"\\n                    limit: 0\\n                    message: internal error! {detailed error}\\n                    row_affect: 0\\n                    row_count: 0\\n                    start_ms: 0\\n                  rows: []\\n                type: sql_endpoint\\n              schema:\\n                $ref: \'#/components/schemas/getHackernewsMentions_per_yearResponse\'\\n          description: Internal server error\\n      summary: /hackernews/mentions_per_year\\n      tags:\\n      - Default\\nsecurity:\\n- basicAuth: []\\nservers:\\n- url: https://us-west-2.data.tidbcloud.com/api/v1beta/app/dataapp-RfFKcZFu/endpoint\\n```\\n\\n</p>\\n</details>\\n\\n##### API Key\\nWhen config this action, you should input the following encoded api key in `Authentication` -> `API Key` -> `Auth Type(Basic)`\\n\\n```\\nQzBTQ0VRNzA6MmJjNjAwYzUtODA0Mi00Yzg4LTkxNTgtMTNiNzdkMDY0OGM5\\n```\\n\\n:::warning Note!\\n* Make sure using this key for GPT\'s learning, thanks~\\n* We will revoke this key after a period of time\\n:::\\n\\n##### Privacy policy\\n```\\nhttps://www.pingcap.com/privacy-policy/\\n```"},{"id":"/how-to-learn-sql-easily-by-visualizing-with-chatgpt","metadata":{"permalink":"/blog/how-to-learn-sql-easily-by-visualizing-with-chatgpt","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/how-to-learn-sql-easily-by-visualizing-with-chatgpt/index.mdx","source":"@site/blog/how-to-learn-sql-easily-by-visualizing-with-chatgpt/index.mdx","title":"How to Learn SQL Easily by Visualizing with ChatGPT","description":"SQL is a powerful language for managing and analyzing data, but it can be difficult to learn for beginners. That\'s where ChatGPT comes in.","date":"2023-03-27T00:00:00.000Z","formattedDate":"March 27, 2023","tags":[{"label":"openai","permalink":"/blog/tags/openai"},{"label":"chatgpt","permalink":"/blog/tags/chatgpt"}],"readingTime":1.95,"hasTruncateMarker":false,"authors":[{"name":"PingCAP","title":"PingCAP provides scaling database infrastructure solutions via an open-source platform.","url":"https://twitter.com/PingCAP","imageURL":"https://github.com/pingcap.png","key":"pingcap"},{"name":"ChatGPT","title":"Robot from OpenAI","url":"https://chat.openai.com/","imageURL":"https://github.com/openai.png","key":"chatgpt"}],"frontMatter":{"title":"How to Learn SQL Easily by Visualizing with ChatGPT","description":"SQL is a powerful language for managing and analyzing data, but it can be difficult to learn for beginners. That\'s where ChatGPT comes in.","date":"2023-03-27T00:00:00.000Z","authors":["pingcap","chatgpt"],"tags":["openai","chatgpt"]},"prevItem":{"title":"Configurations for building \\"Open Source Benchmark\\" GPTs","permalink":"/blog/how-to-build-oss-comparison-gpt"},"nextItem":{"title":"The Unsung Heroes of Open Source: The Dedicated Maintainers Behind Lesser-Known Projects","permalink":"/blog/unsung-heroes-of-open-source"}},"content":"SQL is a powerful language for managing and analyzing data, but it can be difficult to learn for beginners. That\'s where ChatGPT comes in.\\n\\nChatGPT is a large language model trained by OpenAI that can help you learn SQL easily by visualizing the key information in a SQL query. In this blog post, we\'ll show you how to use ChatGPT to visualize SQL queries using pretty ASCII art diagrams.\\nLet\'s start with an example. Suppose we want to find the `top 10 most popular AI projects on GitHub in the last month`. Here\'s the SQL query that does that:\\n\\n```sql\\nSELECT\\n  repo_name,\\n  COUNT(*) AS stars\\nFROM\\n  github_events\\nWHERE\\n  type = \'WatchEvent\'\\n  AND created_at > DATE_SUB(NOW(), INTERVAL 1 MONTH)\\n  AND repo_name LIKE \'%AI%\'\\nGROUP BY\\n  repo_name\\nORDER BY\\n  stars DESC\\nLIMIT\\n  10\\n```\\n\\nNow, let\'s use ChatGPT to `visualize this SQL query using pretty ASCII art diagrams`. Here\'s the diagram:\\n\\n```sql\\n          +-------------------+            \\n          | What to Retrieve? |    top 10 \\n          +-------------------+            \\n                  | SELECT               \\n                  | repo_name,           \\n                  | COUNT(*) AS stars    \\n                  v                      \\n          +-------------------+            \\n          |     From Where?    |    GitHub \\n          +-------------------+            \\n                  | FROM                 \\n                  | github_events        \\n                  v                      \\n          +-------------------+            \\n          |     Filter By:     |    last month, AI projects, most popular \\n          +-------------------+            \\n                  | WHERE                \\n                  | type = \'WatchEvent\'   \\n                  | AND created_at > DATE_SUB(NOW(), INTERVAL 1 MONTH) \\n                  | AND repo_name LIKE \'%AI%\' \\n                  v                      \\n          +-------------------+            \\n          |      Group By      |            \\n          +-------------------+            \\n                  | GROUP BY             \\n                  | repo_name            \\n                  v                      \\n          +-------------------+            \\n          |      Order By      |    most popular \\n          +-------------------+            \\n                  | ORDER BY             \\n                  | stars DESC           \\n                  v                      \\n          +-------------------+            \\n          |     Limit To 10    |    top 10 \\n          +-------------------+            \\n                  | LIMIT                \\n                  | 10                   \\n                  v                      \\n```\\n\\n\\nThis diagram visually shows the flow of the SQL query, from selecting what to retrieve, to filtering, grouping, ordering, and limiting the results. The arrows make it easy to see the relationship between the key information in the question and the corresponding SQL statements.\\n\\n\\nBy using ChatGPT to visualize SQL queries with pretty ASCII art diagrams, you can learn SQL easily and quickly. The diagrams help you understand the structure of the SQL query, and make it easy to see how the various statements are related. With practice, you\'ll be able to write your own SQL queries in no time.\\n\\n\\nIn conclusion, if you want to learn SQL easily, try using ChatGPT to visualize SQL queries with pretty ASCII art diagrams. It\'s a fun and effective way to learn SQL and improve your data management skills."},{"id":"/unsung-heroes-of-open-source","metadata":{"permalink":"/blog/unsung-heroes-of-open-source","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/unsung-heroes-of-open-source/index.mdx","source":"@site/blog/unsung-heroes-of-open-source/index.mdx","title":"The Unsung Heroes of Open Source: The Dedicated Maintainers Behind Lesser-Known Projects","description":"This article will take a closer look at a few of these unsung heroes of the open source world.","date":"2023-03-01T00:00:00.000Z","formattedDate":"March 1, 2023","tags":[{"label":"Maintainer","permalink":"/blog/tags/maintainer"},{"label":"Open Source","permalink":"/blog/tags/open-source"},{"label":"GitHub","permalink":"/blog/tags/git-hub"},{"label":"Core-js","permalink":"/blog/tags/core-js"},{"label":"cURL","permalink":"/blog/tags/c-url"},{"label":"ImageMagick","permalink":"/blog/tags/image-magick"},{"label":"MyCLI","permalink":"/blog/tags/my-cli"},{"label":"Homebrew","permalink":"/blog/tags/homebrew"},{"label":"Apche Log4j","permalink":"/blog/tags/apche-log-4-j"},{"label":"OpenSSL","permalink":"/blog/tags/open-ssl"}],"readingTime":7.37,"hasTruncateMarker":false,"authors":[{"name":"Mia Zhou","title":"Technical Content Developer","url":"https://github.com/luzizhuo","imageURL":"https://github.com/luzizhuo.png","key":"mia"},{"name":"Notion AI","title":"AI assistant from Notion","url":"https://www.notion.so/product/ai","imageURL":"https://upload.wikimedia.org/wikipedia/commons/4/45/Notion_app_logo.png","key":"notionai"}],"frontMatter":{"title":"The Unsung Heroes of Open Source: The Dedicated Maintainers Behind Lesser-Known Projects","description":"This article will take a closer look at a few of these unsung heroes of the open source world.","image":"./core-js-maintainer.png","date":"2023-03-01T00:00:00.000Z","authors":["mia","notionai"],"tags":["Maintainer","Open Source","GitHub","Core-js","cURL","ImageMagick","MyCLI","Homebrew","Apche Log4j","OpenSSL"]},"prevItem":{"title":"How to Learn SQL Easily by Visualizing with ChatGPT","permalink":"/blog/how-to-learn-sql-easily-by-visualizing-with-chatgpt"},"nextItem":{"title":"Get insight from your own data by asking questions without SQL skills","permalink":"/blog/chat2query-tutorials"}},"content":"A few days ago, I read [a blog post by the author of Core-js](https://github.com/zloirock/core-js/blob/master/docs/2023-02-14-so-whats-next.md). To be honest, it was my first time hearing about Core-js. As someone who has written some front-end code and has been keeping up with open source projects, I feel a bit ashamed.\\n\\nHowever, there are many open source projects that are widely used but not well-known. In this blog post, I will take a closer look at a few of these unsung heroes of the open source world. I do not want to give them a business model or financial advice in this article. This largely depends on the author\'s personal experience and values. I just want to raise more awareness about these open source projects.\\n\\n## Core-js\\n\\n- GitHub repo: [https://github.com/zloirock/core-js](https://github.com/zloirock/core-js)\\n\\n[Core-js](https://github.com/zloirock/core-js) is a modular standard library for JavaScript. It provides polyfills for many ECMAScript features, as well as some additional features that are not included in the standard library. It\'s used by many popular JavaScript libraries and frameworks, including React, Vue.js, and Angular.\\n\\nCore-js has been downloaded more than 2.5 billion times from the npm package registry, making it one of the most widely used JavaScript libraries in the world. Despite its widespread use, the project does not receive much attention, and its star growth is very slow.\\n\\nCore-js is maintained by [Denis Pushkarev](https://github.com/zloirock), who started the project as a hobby in 2012 and open-sourced it in 2014.\\n\\n<br />\\n\\n<center>\\n<a href=\\"https://ossinsight.io/explore/?id=b21fdc02-c9dc-4dcf-abc4-f74110e784dc\\" target=\\"_blank\\">\\n<img src={require(\'./core-js-contributors.png\').default} width = \\"90%\\" alt=\\"core-js-contributors\\"/>\\n</a>\\n</center>\\n\\n<center><a href=\\"https://ossinsight.io/explore/?id=b21fdc02-c9dc-4dcf-abc4-f74110e784dc\\" target=\\"_blank\\"><em>Core-js\' top contributors</em></a></center>\\n\\n<br />\\n\\nBased on the distribution of contributions to the project, it seems that Denis has provided more than 95% of the project\'s code. And as he said in the [blog post](https://github.com/zloirock/core-js/blob/master/docs/2023-02-14-so-whats-next.md) I read, the project occupies almost all of his time\u2014more than a full working day.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/zloirock\\" target=\\"_blank\\">\\n        <img src={require(\'./core-js-maintainer.png\').default} width = \\"80%\\" alt=\\"core-js-maintainer\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/zloirock\\" target=\\"_blank\\"><em>Denis\' contribution time distribution</em></a>\\n</center>\\n\\n<br />\\n\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/zloirock/core-js#overview\\" target=\\"_blank\\">\\n        <img src={require(\'./core-js-star.png\').default} width = \\"90%\\" alt=\\"core-js-star\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/zloirock/core-js#overview\\" target=\\"_blank\\"><em>Core-js\' star history</em></a>\\n</center>\\n\\n<br />\\n\\nOn February 14th, Denis\u2019s blog brought significant attention to the Core-js project. Now he has opened multiple donation channels, including through [Open Collective](https://opencollective.com/core-js), [Patreon](https://www.patreon.com/zloirock), and [boosty](https://boosty.to/zloirock). He is actively exploring ways to ensure that Core-js can be maintained in the long term.\\n\\n## cURL\\n\\n- GitHub repo: [https://github.com/curl/curl](https://github.com/curl/curl)\\n\\n[cURL](https://github.com/curl/curl) is a command-line tool and library for transferring data over a wide range of network protocols, including HTTP, FTP, SMTP, and many others. It is used by millions of developers to download and upload files, test APIs, and automate tasks.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=12cbe933-d371-435c-83e6-3fe8d46abf76\\" target=\\"_blank\\">\\n        <img src={require(\'./curl-contributor.png\').default} width = \\"90%\\" alt=\\"curl-contributor\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=12cbe933-d371-435c-83e6-3fe8d46abf76\\" target=\\"_blank\\"><em>cURL\'s top contributors</em></a>\\n</center>\\n\\n<br />\\n\\ncURL is primarily maintained by Daniel Stenberg alone, who started working on the project in 1998. Fortunately, there are occasionally new contributors joining in as mentioned in this[ tweet](https://twitter.com/bagder/status/1628421123586109440). This allows Daniel to maintain a more normal schedule and a full time job, and even[ leave work early on Wednesdays to play floorball](https://twitter.com/bagder/status/1546857830866722817).\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/bagder\\" target=\\"_blank\\">\\n        <img src={require(\'./curl-maintainer.png\').default} width = \\"80%\\" alt=\\"curl-maintainer\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/bagder\\" target=\\"_blank\\"><em>Daniel\'s contribution time distribution</em></a>\\n</center>\\n\\n<br />\\n\\ncURL has received sponsorship from various [organizations](https://curl.se/sponsors.html) and [individuals](https://github.com/sponsors/curl#sponsors), including wolfSSL. WolfSSL employs [Daniel](https://daniel.haxx.se/) and allows him to spend paid work hours on cURL.\\n\\n## ImageMagick\\n\\n- GitHub repo: [https://github.com/ImageMagick/ImageMagick](https://github.com/ImageMagick/ImageMagick)\\n\\nImageMagick is a free and open-source software suite for displaying, converting, and editing raster image and vector image files. ImageMagick is used by millions of websites and applications to manipulate and display images, including popular content management systems like WordPress and Drupal.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=eda659c3-8dfb-41b6-a79e-6ad126797ac1\\" target=\\"_blank\\">\\n    <img src={require(\'./imagemagick-contributor.png\').default} width = \\"90%\\" alt=\\"imagemagick-contributor\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=eda659c3-8dfb-41b6-a79e-6ad126797ac1\\" target=\\"_blank\\"><em>ImageMagick\'s top contributors</em></a>\\n</center>\\n\\n<br />\\n\\nImageMagick is maintained by a small group of developers, including its founder, [John Cristy](https://github.com/urban-warrior). Cristy started the project at DuPont in 1987 and released it in 1990. It is said that John Cristy has a full-time job and only maintains the project in his spare time.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/ImageMagick/ImageMagick#contributors\\" target=\\"_blank\\">\\n    <img src={require(\'./imagemagick-lastmonth.png\').default} width = \\"90%\\" alt=\\"imagemagick-lastmonth\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/ImageMagick/ImageMagick#contributors\\" target=\\"_blank\\"><em>ImageMagick\'s top contributors last month</em></a>\\n</center>\\n\\n<br />\\n\\n[Dirk Lemstra](https://ossinsight.io/analyze/dlemstra) is another primary maintainer of ImageMagick, currently working as a consultant for a company and maintaining the project in his spare time.\\n\\nCurrently, the project is sustained by the support of[ various organizations and individuals](https://imagemagick.org/script/support.php).\\n\\n## MyCLI\\n\\n- GitHub repo:[ https://github.com/dbcli/mycli](https://github.com/dbcli/mycli)\\n\\nMyCLI is a command line interface for MySQL, MariaDB, and Percona with auto-completion and syntax highlighting.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=2ec42ec5-b54b-4103-a01a-90fa72af5137\\" target=\\"_blank\\">\\n        <img src={require(\'./mycli-contributor.png\').default} width = \\"90%\\" alt=\\"mycli-contributor\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=2ec42ec5-b54b-4103-a01a-90fa72af5137\\" target=\\"_blank\\"><em>MyCLI\'s top contributors</em></a>\\n</center>\\n\\n<br />\\n\\nThe project is maintained by its creator, Amjith Ramanujam, and contributions from the open source community. Based on the distribution of contributions, a relatively stable community of contributors has formed around MyCLI. Moreover, there are some[ organizations and individuals sponsoring this project](https://www.mycli.net/sponsors).\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/dbcli/mycli#overview\\" target=\\"_blank\\">\\n        <img src={require(\'./mycli-commit.png\').default} width = \\"90%\\" alt=\\"mycli-commit\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/dbcli/mycli#overview\\" target=\\"_blank\\"><em>MyCLI\'s commit history</em></a>\\n</center>\\n\\n<br />\\n\\nHowever, with the popularity of cloud databases, such projects have fallen behind the times, so the updates for the project have been very slow.\\n\\n## Homebrew\\n\\n- GitHub repo:[ https://github.com/Homebrew/brew](https://github.com/Homebrew/brew)\\n\\nHomebrew is a popular package manager for macOS that allows users to easily install and manage a wide variety of software packages. Homebrew is a nonprofit project run entirely by unpaid volunteer developers, with the lead maintainer being Mike McQuaid.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=791c5932-ceba-44b0-8a34-d5328a177783\\" target=\\"_blank\\">\\n        <img src={require(\'./homebrew-contributor.png\').default} width = \\"90%\\" alt=\\"homebrew-contributor\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=791c5932-ceba-44b0-8a34-d5328a177783\\" target=\\"_blank\\"><em>Homebrew\'s top contributors</em></a>\\n</center>\\n\\n<br />\\n\\n[McQuaid](https://github.com/MikeMcQuaid) has been involved with the Homebrew project since its inception and has been the lead maintainer since 2012\u2014and he has full-time work on GitHub as a principal engineer.\\n\\nHomebrew\u2019s financial operations are managed by the[ Open Source Collective](https://opencollective.com/opensource), and accepts donations through[ GitHub Sponsors](https://github.com/sponsors/Homebrew),[ Open Collective](https://opencollective.com/homebrew) or[ Patreon](https://www.patreon.com/homebrew). Homebrew is also sponsoring some projects, including cURL mentioned earlier.\\n\\n## Apache Log4j\\n\\n- GitHub repo:[ https://github.com/apache/logging-log4j2](https://github.com/apache/logging-log4j2)\\n\\nApache Log4j is a powerful logging framework for Java that allows developers to log messages from their applications with fine-grained control over where and how those messages are recorded. This library has been widely adopted by Java developers and is used by many popular Java-based applications, including Apache Kafka and Apache Spark.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/apache/logging-log4j2#overview\\" target=\\"_blank\\">\\n        <img src={require(\'./log4j2-stars.png\').default} width = \\"90%\\" alt=\\"log4j2-stars\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/analyze/apache/logging-log4j2#overview\\" target=\\"_blank\\"><em>Apache Log4j\'s star history</em></a>\\n</center>\\n\\n<br />\\n\\nInterestingly, the project did not receive much attention until November 2021, when a security vulnerability was reported. This incident doubled its star count and gained attention from the industry.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=63ea8bae-8155-41d2-864c-795978524a60\\" target=\\"_blank\\">\\n        <img src={require(\'./log4j2-contributor.png\').default} width = \\"90%\\" alt=\\"log4j2-contributor\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=63ea8bae-8155-41d2-864c-795978524a60\\" target=\\"_blank\\"><em>Apache Log4j\'s top contributors</em></a>\\n</center>\\n\\n<br />\\n\\n\\n[Ralph Goers](https://github.com/rgoers) is the original author of Log4j 2. He worked on the initial design and development of Log4j 2, which was released in 2014. Now he is working on Nextiva as a Fellow Architect.Now the core maintainer of logging-log4j2 is[ Gary Gregory](https://github.com/garydgregory), who is a member of the Apache Software Foundation and has been working on the project for over a decade.\\n\\nBecause the Log4j 2 project is under the Apache Foundation, the maintainers can focus more on project maintenance without worrying about financial issues.\\n\\n## OpenSSL\\n\\n- GitHub repo:[ https://github.com/openssl/openssl](https://github.com/openssl/openssl)\\n\\nOpenSSL is an open source library that provides cryptographic functions for many different applications, including web servers, email clients, and virtual private networks. OpenSSL is used by millions of websites and applications to secure communications over the internet, including popular web servers like Apache and Nginx, as well as popular programming languages like Python and Ruby.\\n\\n<br />\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=143a8231-bd81-42c7-bb52-d1e85c61c6a9\\" target=\\"_blank\\">\\n    <img src={require(\'./openssl-contributor.png\').default} width = \\"90%\\" alt=\\"openssl-contributor\\"/>\\n    </a>\\n</center>\\n\\n<center>\\n    <a href=\\"https://ossinsight.io/explore/?id=143a8231-bd81-42c7-bb52-d1e85c61c6a9\\" target=\\"_blank\\"><em>OpenSSL\'s top contributors</em></a>\\n</center>\\n\\n<br />\\n\\nThe project is developed by a distributed team, mostly consisting of volunteers with some project funded resources. The team is led by[ Matt Caswell](https://github.com/mattcaswell), who has been working on OpenSSL since 2010 and became one of the maintainers in 2013.\\n\\nApart from volunteer developers, OpenSSL also depends on financial support from the community, which can be given in various forms. These include[ a support contract](https://www.openssl.org/support/contracts.html),[ a sponsorship donation](https://www.openssl.org/support/acks.html), or a smaller donation via[ GitHub Sponsors](https://github.com/sponsors/openssl).\\n\\nMaintaining an open source project is no easy feat. It\'s a labor of love, built by passionate developers who sacrifice their time to create something that makes a difference. As users, we owe them our gratitude for the tools and technologies they provide. As Mike McQuaid suggested on the blog[ Open Source Maintainers Owe You Nothing](https://mikemcquaid.com/open-source-maintainers-owe-you-nothing/), \\"Remember when filing an issue, opening a pull request, or making a comment on a project, to be grateful that people spend their free time to build software you get to use for free.\\""},{"id":"/chat2query-tutorials","metadata":{"permalink":"/blog/chat2query-tutorials","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/chat2query-tutorials/index.mdx","source":"@site/blog/chat2query-tutorials/index.mdx","title":"Get insight from your own data by asking questions without SQL skills","description":"Get insight of your own dataset by asking questions without writing sql with ease!","date":"2023-01-08T00:00:00.000Z","formattedDate":"January 8, 2023","tags":[{"label":"openai","permalink":"/blog/tags/openai"},{"label":"chatgpt","permalink":"/blog/tags/chatgpt"}],"readingTime":0.725,"hasTruncateMarker":false,"authors":[{"name":"PingCAP","title":"PingCAP provides scaling database infrastructure solutions via an open-source platform.","url":"https://twitter.com/PingCAP","imageURL":"https://github.com/pingcap.png","key":"pingcap"},{"name":"ChatGPT","title":"Robot from OpenAI","url":"https://chat.openai.com/","imageURL":"https://github.com/openai.png","key":"chatgpt"}],"frontMatter":{"title":"Get insight from your own data by asking questions without SQL skills","description":"Get insight of your own dataset by asking questions without writing sql with ease!","date":"2023-01-08T00:00:00.000Z","authors":["pingcap","chatgpt"],"tags":["openai","chatgpt"]},"prevItem":{"title":"The Unsung Heroes of Open Source: The Dedicated Maintainers Behind Lesser-Known Projects","permalink":"/blog/unsung-heroes-of-open-source"},"nextItem":{"title":"Reducing Online Serving Latency from 1.11s to 123.6ms on a Distributed SQL Database","permalink":"/blog/reduce-query-latency"}},"content":"import mp4URLL from \'./how-to-use-chat2query.mp4\';\\n\\n> This blog is written with help of ChatGPT.\\n\\n<br />\\n\\nTo get insight of your own dataset without writing sql is easy, follow these steps:\\n\\n1. Sign up for a TiDB Cloud account at [https://tidbcloud.com/](https://tidbcloud.com/channel/?utm_source=ossinsight&utm_medium=community&utm_campaign=chat2query_202301) using your email, Google account, or GitHub account.\\n\\n2. Create a free Serverless Tier cluster in the TiDB Cloud web console.\\n\\n3. In the TiDB Cloud web console, click the \\"Import\\" button and follow the prompts to load a CSV file into your cluster from a local file or from Amazon S3.\\n\\n  ![Import Data](./import.png)\\n\\n4. Use the web console\'s SQL editor(Chat2Query) to get insights from your data. But no worry, you don\'t need to write SQL, you could ask questions about your data in natural language.\\n\\n  The magic is typing `-- your question` and press Enter, here is an example:\\n\\n  <video src={mp4URLL} width=\\"100%\\" autoplay controls></video>"},{"id":"/reduce-query-latency","metadata":{"permalink":"/blog/reduce-query-latency","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/reduce-query-latency/index.mdx","source":"@site/blog/reduce-query-latency/index.mdx","title":"Reducing Online Serving Latency from 1.11s to 123.6ms on a Distributed SQL Database","description":"This post tells how a GitHub data insight website on a distributed database reduced online serving latency from 1.11s to 123.6ms.","date":"2022-11-17T00:00:00.000Z","formattedDate":"November 17, 2022","tags":[{"label":"tidbcloud","permalink":"/blog/tags/tidbcloud"}],"readingTime":10.525,"hasTruncateMarker":false,"authors":[{"name":"Mini256","title":"Engineer of TiDB Community","url":"https://github.com/Mini256","imageURL":"https://github.com/Mini256.png","key":"Mini256"},{"name":"Caitin Chen","title":"Technical Content Developer","url":"https://github.com/CaitinChen","imageURL":"https://github.com/caitinchen.png","key":"caitin"}],"frontMatter":{"title":"Reducing Online Serving Latency from 1.11s to 123.6ms on a Distributed SQL Database","date":"2022-11-17T00:00:00.000Z","authors":["Mini256","caitin"],"tags":["tidbcloud"],"image":"./reduce-online-serving-latency-with-distributed-sql-database.jpg","description":"This post tells how a GitHub data insight website on a distributed database reduced online serving latency from 1.11s to 123.6ms.","keywords":["open source","database","distributed sql database"]},"prevItem":{"title":"Get insight from your own data by asking questions without SQL skills","permalink":"/blog/chat2query-tutorials"},"nextItem":{"title":"Open Source Highlights: Trends and Insights from GitHub 2022","permalink":"/blog/trends-and-insights-from-github-2022"}},"content":"**_TL;DR:_**\\n\\n_This post tells how a website on a distributed database **reduced online serving latency from 1.11 s to 417.7 ms, and then to 123.6 ms**. We found that some lessons learned on MySQL could be applied throughout the optimization process. But when we optimize a **distributed database,** we need to consider more._\\n\\nThe [OSS Insight](https://ossinsight.io/) website displays the data changes of GitHub events in real time. It\'s powered by [TiDB Cloud](https://www.pingcap.com/tidb-cloud/), a MySQL-compatible distributed SQL database for elastic scale and real-time analytics.\\n\\nRecently, to save costs, we tried to use lower-specification machines without affecting query efficiency and user experience. But our website and query response slowed down.\\n\\n<br />\\n\\n![The repository analysis page was loading](./repository-analysis-page.jpg)\\n\\n<center><em>The repository analysis page was loading, loading, and loading</em></center>\\n\\n<br />\\n\\nHow could we solve these problems on a distributed database? Could we use the methodology we learned on MySQL?\\n\\n## Analyzing the SQL execution plan\\n\\nTo identify slow SQL statements, we used TiDB Cloud\'s Diagnosis page to sort SQL queries by their average latency.\\n\\nFor example, after the API server received a request, it executed the following SQL statement to obtain the number of issues in the [vscode repository](https://ossinsight.io/analyze/microsoft/vscode):\\n\\n```sql\\nSELECT\\n    COUNT(DISTINCT number)\\nFROM github_events\\nWHERE\\n    repo_id = 41881900     -- vscode\\n    AND type = \'IssuesEvent\';\\n```\\n\\nHowever, if the open source repository is large, this query may take several seconds or more to execute.\\n\\n### Using `EXPLAIN ANALYZE` to troubleshoot query performance problems\\n\\nIn MySQL, when we troubleshoot query performance problems, we usually use the `EXPLAIN ANALYZE <sql>` statement to view the SQL statement\'s execution plan. We can use the execution plan to locate the problem. The same works for TiDB.\\n\\nWe executed the `EXPLAIN` statement:\\n\\n```sql\\nEXPLAIN ANALYZE SELECT\\n    COUNT(DISTINCT number)\\nFROM github_events\\nWHERE\\n    repo_id = 41881900     -- vscode\\n    AND type = \'IssuesEvent\';\\n```\\n\\nThe result showed that the query took 1.11 seconds to execute.\\n\\n<br />\\n\\n![The query result](./query-result.jpg)\\n\\n<center><em>The query result</em></center>\\n\\n<br />\\n\\nYou can see that TiDB\'s [`EXPLAIN ANALYZE`](https://docs.pingcap.com/tidb/stable/explain-overview) statement execution result was completely different from MySQL\'s. TiDB\'s execution plan gave us a clearer understanding of how this SQL statement was executed.\\n\\nThe execution plan shows:\\n\\n* This SQL statement was split into several subtasks. Some were on the `root` node, and others were on the [`tikv`](https://docs.pingcap.com/tidb/dev/tikv-overview#tikv-overview) node.\\n* The query fetched data from the `partition:issue_event partition` table.\\n* This query did a range scan through the index `index_github_events_on_repo_id(repo_id)`. This let the query **narrow down the data scan quickly**. **This process only took** **59 ms.** It was the sum of the execution times of multiple concurrent tasks.\\n* Besides `IndexRangeScan`, **the query also used `TableRowIDScan`**. **This scan took** **4.69 s**, the sum of execution times for multiple concurrent subtasks.\\n\\nFrom the execution times above, we determined that the query performance bottleneck was in the `TableRowIDScan` step.\\n\\nWe reran the `EXPLAIN ANALYZE` statement and found that the query was faster the second time. Why?\\n\\n### Why did `TableRowIDScan` take so long?\\n\\nTo find the reason why `TableRowIDScan` took so long, we need basic knowledge of TiDB\'s underlying storage.\\n\\nIn TiDB, a table\'s data entries and indexes are stored on TiKV nodes in key-value pairs.\\n\\n* For an index, the key is the combination of the index value and the `row_id` (for a non-clustered index) or the primary key (for a clustered index). The `row_id` or primary key indicates where the data is stored.\\n* For a data entry, the key is the combination of the table ID and the `row_id` or primary key. The value part is the combination of this row of data.\\n\\nThis graph shows how `IndexLookup` is executed in the execution plan:\\n\\n<br />\\n\\n![The logical structure](./logical-structure.jpg)\\n\\n<center><em>This is the logical structure, not the physical storage structure.</em></center>\\n\\n<br />\\n\\nIn the query above, TiDB uses the query condition `repo_id=41881900` to filter out all row numbers `row_id` related to the repository in the secondary index `index_github_events_on_repo_id`. The query needs the number `column` data, but the secondary index doesn\'t provide it. Therefore, TiDB must execute `IndexLookup` to find the corresponding row in the table based on the obtained `row_id` (the `TableRowIDScan` step).\\n\\nThe rows are probably scattered in different data blocks and stored on the hard disk. This causes TiDB to perform a large number of I/O operations to read data from different data blocks or even different machine nodes.\\n\\n### Why was `EXPLAIN ANALYZE` faster the second time?\\n\\nIn `EXPLAIN ANALYZE`\'s execution result, we saw that the \\"execution info\\" column corresponding to the `TableRowIDScan` step contained this information:\\n\\n```\\nblock: {cache_hit_count: 2755559, read_count: 179510, read_byte: 4.07 GB}\\n```\\n\\nWe thought this had something to do with TiKV. TiKV read a very large number of data blocks from the disk. Because the data blocks read from the _disk_ were cached in _memory_ in the first execution, 2.75 million data blocks could be read directly from _memory_ instead of being retrieved from the hard disk. This made the `TableRowIDScan` step much faster, and the query was faster overall.\\n\\nHowever, we believed that user queries were random. For example, a user might look up data from a `vscode` repository and then go to a `kubernetes` repository. TiKV\'s memory couldn\'t cache all the data blocks in all the drives. Therefore, this did not solve our problem, but it reminded us that when we analyze SQL execution efficiency, we need to exclude cache effects.\\n\\n## Using a covering index to avoid executing `TableRowIDScan`\\n\\nCould we avoid executing `TableRowIDScan` in `IndexLookup`?\\n\\nIn MySQL, a covering index prevents the database from index lookup after index filtering. We wanted to apply this to OSS Insight. In our TiDB database, we tried to create a composite index to achieve index coverage.\\n\\nWhen we created a composite index with multiple columns, we needed to pay attention to the column order. Our goals were to allow a composite index to be used by as many queries as possible, to help these queries narrow the scope of data scans as quickly as possible, and to provide as many fields as possible in the query. When we created a composite index we followed this order:\\n\\n1. Columns that had high differentiation and could be used as equivalence conditions for the `WHERE` statement, like `repo_id`\\n2. Columns that didn\'t have high differentiation but could be used as equivalence conditions for the `WHERE` statement, like `type` and `action`\\n3. Columns that could be used as range query conditions for the `WHERE` statement, like `created_at`\\n4. Redundant columns that were not used as filter conditions but were used in the query, such as `number` and `push_size`\\n\\nWe used the `CREATE INDEX` statement to create a composite index in the database:\\n\\n```\\nCREATE INDEX index_github_events_on_repo_id_type_number ON github_events(repo_id, type, number);\\n```\\n\\nWhen we created the index and ran the SQL statement again, the query speed was significantly faster. We viewed the execution plan through `EXPLAIN ANALYZE` and found that the execution plan became simpler. The `IndexLookup` and `TableRowIDScan` steps were gone. **The query took only 417.7 ms**.\\n\\n<br />\\n\\n![The result of the EXPLAIN query](./explain-query-result.jpg)\\n\\n<center><em>The result of the EXPLAIN query. This query cost 417.7 ms</em></center>\\n\\n<br />\\n\\nSo we knew that our query could get all the data it needed by doing an `IndexRangeScan` on the new index. This composite index included the `number` field, so TiDB did not need to perform `IndexLookup` to get data from the table. This reduced a lot of I/O operations.\\n\\n<br />\\n\\n![`IndexRangeScan` in the non-clustered table](./indexrangescan-non-clustered.jpg)\\n\\n<center><em>IndexRangeScan in the non-clustered table</em></center>\\n\\n<br />\\n\\n## Pushing down computing to further reduce query latency\\n\\nFor a query that needed to obtain 270,000 rows of data, 417.7 ms was quite a short execution time. But could we improve the time even more?\\n\\nWe thought this relied on TiDB\'s architecture that separates computing and storage layers. This is different from MySQL.\\n\\nIn TiDB:\\n\\n* The `tidb-server` node computes data. It corresponds to root in the execution plan.\\n* The `tikv-server` node stores the data. It corresponds to `cop[tikv]` in the execution plan.\\n\\nGenerally, an SQL statement is split into multiple steps to execute with the cooperation of computing and storage nodes.\\n\\nWhen we executed the SQL statement in this article, TiDB obtained the data of the `github_events` table from `tikv-server` and performed the aggregate calculation of the COUNT function on `tidb-server`.\\n\\n```sql\\nSELECT\\n    COUNT(DISTINCT number)\\nFROM github_events\\nWHERE\\n    repo_id = 41881900     -- vscode\\n    AND type = \'IssuesEvent\';\\n```\\n\\nThe execution plan indicated that when TiDB was performing `IndexReader`, `tidb-server` needed to read 270,000 rows of data from `tikv-server` through the network. This was time-consuming.\\n\\n<br />\\n\\n![`tidb-server` read 270,000 rows of data from `tikv-server`](./read-270000-rows-from-tikv-server.jpg)\\n\\n<center><em>tidb-server read 270,000 rows of data from tikv-server</em></center>\\n\\n<br />\\n\\nHow could we avoid such a large network transmission? Although the query needed to obtain a large amount of data, the final calculation result was only a number. Could we complete the `COUNT` aggregation calculation on `tikv-server` and return the result only to `tidb-server`?\\n\\nTiDB had implemented this idea through the [coprocessor](https://docs.pingcap.com/tidb/dev/tikv-overview#tikv-coprocessor) on `tikv-server`. This optimization process is called computing pushdown.\\n\\nThe execution plan indicated that our SQL query did not do this. Why? We checked the TiDB documentation and learned that:\\n\\n> Usually, aggregate functions with the `DISTINCT` option are executed in the TiDB layer in a single-threaded execution model.\\n\\nThis meant that our SQL statement couldn\'t use computing pushdown.\\n\\n```sql\\nSELECT\\n    COUNT(DISTINCT number)\\nFROM github_events\\nWHERE\\n    repo_id = 41881900     -- vscode\\n    AND type = \'IssuesEvent\';\\n```\\n\\nTherefore, we removed the `DISTINCT` keyword.\\n\\nFor the `github_events` table, an issue only generated an event with the `IssuesEvent` type and `opened` action. We could get the total number of unique issues by adding the condition of `action = \'opened\'`. This way, we didn\'t need to use the `DISTINCT` keyword for deduplication.\\n\\n```\\nSELECT\\n    COUNT(number)\\nFROM github_events\\nWHERE\\n    repo_id = 41881900     -- vscode\\n    AND type = \'IssuesEvent\'\\n    AND action = \'opened\';\\n```\\n\\nThe composite index we created lacked the `action` column. This caused the query index coverage to fail. So we created a new composite index:\\n\\n```\\nCREATE INDEX index_github_events_on_repo_id_type_action_number ON github_events(repo_id, type, action, number);\\n```\\n\\nAfter we created the index, we checked the execution plan of the modified SQL statement through the `EXPLAIN ANALYZE` statement. We found that:\\n\\n* Because we added a new filter `action=\'opened\'`, the number of rows to scan had decreased from 270,000 to 140,000.\\n* `tikv-server` executed the `StreamAgg` operator, which was the aggregate calculation of the `COUNT` function. This indicated that the calculation had been pushed down to the TiKV coprocessor for execution.\\n* `tidb-server` only needed to obtain two rows of data from `tikv-server` through the network. This greatly reduced the amount of data transmitted.\\n* The query only took 123.6 ms.\\n\\n```\\n+-------------------------+---------+---------+-----------+-------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-----------+------+\\n| id                      | estRows | actRows | task      | access object                                                                                                           | execution info                                                                                                                                                                                                                                                                                                                                                           | operator info                                                                             | memory    | disk |\\n+-------------------------+---------+---------+-----------+-------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-----------+------+\\n| StreamAgg_28            | 1.00    | 1       | root      |                                                                                                                         | time:123.6ms, loops:2                                                                                                                                                                                                                                                                                                                                                    | funcs:count(Column#43)->Column#34                                                         | 388 Bytes | N/A  |\\n| \u2514\u2500IndexReader_29        | 1.00    | 2       | root      | partition:issues_event                                                                                                  | time:123.6ms, loops:2, cop_task: {num: 2, max: 123.5ms, min: 1.5ms, avg: 62.5ms, p95: 123.5ms, max_proc_keys: 131360, p95_proc_keys: 131360, tot_proc: 115ms, tot_wait: 1ms, rpc_num: 2, rpc_time: 125ms, copr_cache_hit_ratio: 0.50, distsql_concurrency: 15}                                                                                                           | index:StreamAgg_11                                                                        | 590 Bytes | N/A  |\\n|   \u2514\u2500StreamAgg_11        | 1.00    | 2       | cop[tikv] |                                                                                                                         | tikv_task:{proc max:116ms, min:8ms, avg: 62ms, p80:116ms, p95:116ms, iters:139, tasks:2}, scan_detail: {total_process_keys: 131360, total_process_keys_size: 23603556, total_keys: 131564, get_snapshot_time: 1ms, rocksdb: {delete_skipped_count: 320, key_skipped_count: 131883, block: {cache_hit_count: 307, read_count: 1, read_byte: 63.9 KB, read_time: 60.2\xb5s}}} | funcs:count(gharchive_dev.github_events.number)->Column#43                                | N/A       | N/A  |\\n|     \u2514\u2500IndexRangeScan_15 | 7.00    | 141179  | cop[tikv] | table:github_events, index:index_ge_on_repo_id_type_action_created_at_number(repo_id, type, action, created_at, number) | tikv_task:{proc max:116ms, min:8ms, avg: 62ms, p80:116ms, p95:116ms, iters:139, tasks:2}                                                                                                                                                                                                                                                                                 | range:[41881900 \\"IssuesEvent\\" \\"opened\\",41881900 \\"IssuesEvent\\" \\"opened\\"], keep order:false | N/A       | N/A  |\\n+-------------------------+---------+---------+-----------+-------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+-----------+------+\\n```\\n\\n## Applying what we learned to other queries\\n\\n**Through our analysis and optimizations, the query latency was significantly reduced:**\\n\\n**1.11 s \u2192 417.7 ms \u2192 123.6 ms**\\n\\nWe applied what we learned to other queries and created the following composite indexes in the `github_events` table:\\n\\n```\\nindex_ge_on_repo_id_type_action_pr_merged_created_at_add_del\\n\\nindex_ge_on_repo_id_type_action_created_at_number_pdsize_psize\\n\\nindex_ge_on_repo_id_type_action_created_at_actor_login\\n\\nindex_ge_on_creator_id_type_action_merged_created_at_add_del\\n\\nindex_ge_on_actor_id_type_action_created_at_repo_id_commits\\n```\\n\\nThese composite indexes covered more than 20 analytical queries in repository analysis and personal analysis pages on the OSS Insight website. This improved our website\'s overall loading speed.\\n\\n**Some lessons we learned on MySQL can be applied throughout the optimization process.** But we need to consider more when we optimize query performance in a **distributed database**. We also recommend you read [Performance Tuning](https://docs.pingcap.com/tidb/stable/performance-tuning-overview) in the TiDB documentation. This will give you a more professional and comprehensive guide to performance optimization.\\n\\n## References\\n\\n* [TiDB Computing](https://docs.pingcap.com/tidb/dev/tidb-computing)\\n* [TiDB Storage](https://docs.pingcap.com/tidb/stable/tidb-storage)\\n* [Distinct Optimization](https://docs.pingcap.com/tidb/stable/agg-distinct-optimization)"},{"id":"/trends-and-insights-from-github-2022","metadata":{"permalink":"/blog/trends-and-insights-from-github-2022","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/trends-and-insights-from-github-2022/index.mdx","source":"@site/blog/trends-and-insights-from-github-2022/index.mdx","title":"Open Source Highlights: Trends and Insights from GitHub 2022","description":"We analyzed 5 billion+ GitHub events and got interesting findings about open source software, including top programming languages, geographic distribution behavior, popular open source topics, and the most active repositories and developers.","date":"2022-11-09T00:00:00.000Z","formattedDate":"November 9, 2022","tags":[{"label":"insight","permalink":"/blog/tags/insight"}],"readingTime":9.88,"hasTruncateMarker":false,"authors":[{"name":"Cheese Wong","title":"Engineer of TiDB Community","url":"https://github.com/Icemap","imageURL":"https://github.com/Icemap.png","key":"cheese"},{"name":"Jagger","title":"Engineer of TiDB Community","url":"https://github.com/634750802","imageURL":"https://github.com/634750802.png","key":"Jagger"},{"name":"hooopo","title":"Engineer of TiDB Community","url":"https://twitter.com/hooopo","imageURL":"https://github.com/hooopo.png","key":"hooopo"},{"name":"Vita Lu","title":"Developer Relations Engineer","url":"https://github.com/ChenlingLu","imageURL":"https://github.com/ChenlingLu.png","key":"vita"},{"name":"Mia Zhou","title":"Technical Content Developer","url":"https://github.com/luzizhuo","imageURL":"https://github.com/luzizhuo.png","key":"mia"},{"name":"Caitin Chen","title":"Technical Content Developer","url":"https://github.com/CaitinChen","imageURL":"https://github.com/caitinchen.png","key":"caitin"}],"frontMatter":{"title":"Open Source Highlights: Trends and Insights from GitHub 2022","date":"2022-11-09T00:00:00.000Z","authors":["cheese","Jagger","hooopo","vita","mia","caitin"],"tags":["insight"],"image":"./open-source-highlights-trends-and-insights-from-github-2022.png","description":"We analyzed 5 billion+ GitHub events and got interesting findings about open source software, including top programming languages, geographic distribution behavior, popular open source topics, and the most active repositories and developers.","keywords":["github annual report","github 2022","github insights","open source","top programming languages","most active developers","most active repositories"]},"prevItem":{"title":"Reducing Online Serving Latency from 1.11s to 123.6ms on a Distributed SQL Database","permalink":"/blog/reduce-query-latency"},"nextItem":{"title":"GitHub Events Are Booming! Are Bots the Reason?","permalink":"/blog/github-data-is-booming"}},"content":"We analyzed more than 5,000,000,000 rows of GitHub event data and got the results here. In this [report](https://ossinsight.io/2022/), you\'ll get interesting findings about open source software on GitHub in 2022, including:\\n\\n- [Top languages in the open source world over the past four years](#top-languages-in-the-open-source-world-over-the-past-four-years)\\n- [Geographic distribution of developer behavior](#geographic-distribution-of-developer-behavior)\\n- [Developer behavior distribution on weekdays and weekends](#developer-behavior-distribution-on-weekdays-and-weekends)\\n- [Popular open source topics](#popular-open-source-topics)\\n- [The most popular repositories in 2022](#the-most-popular-repositories-in-2022)\\n- [The most active repositories over the past four years](#the-most-active-repositories-over-the-past-four-years)\\n- [Who gave the most stars in 2022](#who-gave-the-most-stars-in-2022)\\n- [The most active developers since 2011](#the-most-active-developers-since-2011)\\n- [Appendix](#appendix)\\n\\n## Top languages in the open source world over the past four years\\n\\nThis chart ranks programming languages yearly from 2019 to 2022 based on the ratio of new repositories using these languages to all new repositories.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./top-programming-languages.png\').default} width = \\"80%\\" alt=\\"top-programming-languages\\"/>\\n</center>\\n\\n<center><em>Top programming languages</em></center>\\n\\n<br />\\n\\nInsights:\\n\\n* Python surpassed Java and moved to #3 in 2021.\\n* TypeScript rose from #10 to #6, and SCSS rose from #39 to #19. The rise of SCSS shows that open source projects that value front-end expressiveness are gradually gaining popularity.\\n* The two languages Ruby and R dropped a lot in ranking over the years.\\n\\n### Rankings of back-end programming languages\\n\\nThe programming languages used in a pull request reflect which languages developers used. To find out the most popular back-end programming languages, we queried the distribution of programming languages by new pull requests from 2019 to 2022 and took the top 10 for each year.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./top-back-end-programming-languages.png\').default} width = \\"80%\\" alt=\\"top-back-end-programming-languages\\"/>\\n</center>\\n\\n<center><em>Top back-end programming languages</em></center>\\n\\n<br />\\n\\nThe chart data indicates:\\n\\n* Python and Java rank #1 and #2 respectively. In 2021, Go overtook Ruby to rank #3 in 2021.\\n* Rust has been trending upward for several years, ranking #9 in 2022.\\n\\n## Geographic distribution of developer behavior\\n\\nWe queried the number of various events that occurred throughout the world from January 1 to September 30, 2022 and identified the top 10 countries by the number of events triggered by developers in these countries. The chart displays the proportion of each event type by country or region.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./geographic-distribution-of-developer-behavior.png\').default} width = \\"80%\\" alt=\\"geographic-distribution-of-developer-behavior\\"/>\\n</center>\\n\\n<center><em>Geographic distribution of developer behavior</em></center>\\n\\n<br />\\n\\nThe chart shows that:\\n\\n* The events triggered in the top 10 countries account for about 23.27% of all GitHub events. However, the number of developers from these countries is only 10%.\\n* US developers are most likely to review code, with a PullRequestReviewEvent share of 6.15%.\\n* Korean developers prefer pushing directly to repositories (PushEvent).\\n* Japanese developers are most likely to submit code via pull requests, with a PullRequestEvent share of 10%.\\n* German developers like to open issues and comments, with IssueEvent and CommentEvent accounting for 4.18% and 12.66% respectively.\\n* Chinese developers like to star repositories, with 17.23% for WatchEvent and 2.7% for ForkEvent.\\n\\nNotes:\\n\\n* In 2022, 17,062,081 developers had behavioral events, and 2,923,523 of them have the Location field, so the sampling rate is 17.13%\\n* GitHub identifies 15 types of events. We only show commonly used types. Comment Event includes CommitCommentEvent, IssueCommentEvent, and PullRequestReviewCommentEvent. Others includes MemberEvent, CreateEvent, ReleaseEvent, GollumEvent, and PublicEvent.\\n\\n## Developer behavior distribution on weekdays and weekends\\n\\nWe queried the distribution of each event type over the seven days of the week.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./developer-behavior-distribution-on-weekdays-and-weekends.png\').default} width = \\"80%\\" alt=\\"developer-behavior-distribution-on-weekdays-and-weekends\\"/>\\n</center>\\n\\n<center><em>Developer behavior distribution on weekdays and weekends</em></center>\\n\\n<br />\\n\\nInsights:\\n\\n* Developers are most active on weekdays, with 77.73% of events occurring on weekdays.\\n\\n### The distribution of specific events\\n\\n<center>\\n<img src={require(\'./developer-behavior-distribution-from-monday-to-sunday.png\').default} width = \\"80%\\" alt=\\"developer-behavior-distribution-from-monday-to-sunday\\"/>\\n</center>\\n\\n<center><em>Developer behavior distribution from Monday to Sunday</em></center>\\n\\n<br />\\n\\nInsights:\\n\\n* Pull Request Event, Pull Request Review Event, and Issues Event all have the highest percentage on Tuesdays, while the lowest percentage is on the weekends.\\n* The amount of Push Event, Watch Event, and Fork Event activities are similar on weekdays and weekends, while the Pull Request Review Event is the most different. Watch Event and Fork Event are more personal behaviors, Pull Request Review Events are more work behaviors, and Push Events are used more in personal projects.\\n\\n## Popular open source topics\\n\\nEach year, technology introduces new buzz words. Can we gain insight into technical trends through the open source repositories behind the hot words? We investigated five technical areas: Low Code, Web3, GitHub Actions, Database, and AI.\\n\\n### Activity levels of popular topics\\n\\nWe queried the number of open source repositories associated with each technical area, as well as the percentage of active repositories in 2022.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./activity-levels-of-popular-topics.png\').default} width = \\"80%\\" alt=\\"activity-levels-of-popular-topics\\"/>\\n</center>\\n\\n<center><em>Activity levels of popular topics</em></center>\\n\\n<br />\\n\\nThis figure shows that open source repositories in the Low Code topic are the most active, with 76.3% being active in 2022, followed by Web3 with 63.85%.\\n\\n### Popular topics over the years\\n\\nWe queried the following items for each technical area from 2015 to 2022:\\n\\n* The annual increment of repositories\\n* The annual increment of collaborative events\\n* The number of developers participating in collaborative events\\n* The annual increment of stars\\n\\nThen, we calculated the growth rate for each year which can reflect new entrants, developer engagement in this technical field, and the industry\'s interest in this area. For 2022, we compare its first nine months with the first nine months of 2021.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./low-code-repositories.png\').default} width = \\"80%\\" alt=\\"low-code-repositories\\"/>\\n</center>\\n\\n<center><em>Low code repositories</em></center>\\n\\n<br />\\n\\nWe can see that 2020 is the peak period of project development, with a 313.43% increase in new repositories and a 157.06% increase in developer collaborative events. The industry\'s interest increased most significantly in 2021, reaching 184.82%. In 2022, the year-on-year growth data shows that the number of new repositories decreased (-26.21%), but developer engagement and industry interest are still rising.\\n\\n\\\\* Time range of 2022: 01.01-09.30, excluding bot events and forking repositories\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./web3-repositories.png\').default} width = \\"80%\\" alt=\\"web3-repositories\\"/>\\n</center>\\n\\n<center><em>Web3 repositories</em></center>\\n\\n<br />\\n\\nWhether it is the creation of new repositories, developers, or the interest of the industry, the Web3 ecosystem has grown rapidly in recent years, and the growth rate of new repositories peaked at 322.65% in 2021.\\n\\n\\\\* Time range of 2022: 01.01-09.30, excluding bot events and forking repositories\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./github-actions-repositories.png\').default} width = \\"80%\\" alt=\\"github-actions-repositories\\"/>\\n</center>\\n\\n<center><em>GitHub Actions repositories</em></center>\\n\\n<br />\\n\\nThe annual increase of GitHub Actions repositories has been declining, but developer engagement and the industry\'s interest are still increasing slightly.\\n\\n\\\\* Time range of 2022: 01.01-09.30, excluding bot events and forking repositories\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./database-repositories.png\').default} width = \\"80%\\" alt=\\"database-repositories\\"/>\\n</center>\\n\\n<center><em>Database repositories</em></center>\\n\\n<br />\\n\\nAs an infrastructure project, the Database project\'s threshold is high. Compared with projects in other fields, a database project has a stable growth rate.\\n\\n\\\\* Time range of 2022: 01.01-09.30, excluding bot events and forking repositories\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./ai-repositories.png\').default} width = \\"80%\\" alt=\\"ai-repositories\\"/>\\n</center>\\n\\n<center><em>AI repositories</em></center>\\n\\n<br />\\n\\nAfter two years of high growth in 2016 and 2017, open source projects in AI have been growing gradually slowly.\\n\\n\\\\* Time range of 2022: 01.01-09.30, excluding bot events and forking repositories\\n\\n## The most popular repositories in 2022\\n\\nThe number of stars is the most visible indication of the popularity of open source projects. We looked at the 50 projects that received the most stars from January 1 to September 30, 2022. We found that:\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./most-popular-repositories-2022.png\').default} width = \\"80%\\" alt=\\"most-popular-repositories-2022\\"/>\\n</center>\\n\\n<center><em>The most popular repositories in 2022</em></center>\\n\\n<br />\\n\\n\\\\* Time range: 2022.01.01-2022.09.30, excluding bot events\\n\\n## The most active repositories over the past four years\\n\\nHere we looked up the top 20 active repositories per year from 2019 to 2022 and counted the total number of listings per repository. The activity of the repository is ranked according to the number of developers participating in collaborative events.\\n\\n<table>\\n  <tr>\\n   <td><strong>Repository Name</strong>\\n   </td>\\n   <td><strong>Count</strong>\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/microsoft/vscode\\">microsoft/vscode</a>\\n   </td>\\n   <td>4\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/flutter/flutter\\">flutter/flutter</a>\\n   </td>\\n   <td>4\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/MicrosoftDocs/azure-docs\\">MicrosoftDocs/azure-docs</a>\\n   </td>\\n   <td>4\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/firstcontributions/first-contributions\\">firstcontributions/first-contributions</a>\\n   </td>\\n   <td>4\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/Facebook/react-native\\">Facebook/react-native</a>\\n   </td>\\n   <td>4\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/pytorch/pytorch\\">pytorch/pytorch</a>\\n   </td>\\n   <td>4\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/microsoft/TypeScript\\">microsoft/TypeScript</a>\\n   </td>\\n   <td>4\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/tensorflow/tensorflow\\">tensorflow/tensorflow</a>\\n   </td>\\n   <td>3\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/kubernetes/kubernetes\\">kubernetes/kubernetes</a>\\n   </td>\\n   <td>3\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/DefinitelyTyped/DefinitelyTyped\\">DefinitelyTyped/DefinitelyTyped</a>\\n   </td>\\n   <td>3\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/golang/go\\">golang/go</a>\\n   </td>\\n   <td>3\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/google/it-cert-automation-practice\\">google/it-cert-automation-practice</a>\\n   </td>\\n   <td>3\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/home-assistant/core\\">home-assistant/core</a>\\n   </td>\\n   <td>3\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/microsoft/PowerToys\\">microsoft/PowerToys</a>\\n   </td>\\n   <td>3\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><a href=\\"https://ossinsight.io/analyze/microsoft/WSL\\">microsoft/WSL</a>\\n   </td>\\n   <td>3\\n   </td>\\n  </tr>\\n</table>\\n\\nInsights:\\n\\n* Microsoft has the most repositories on the list, with five.\\n* tensorflow/tensorflow and kubernetes/kubernetes both dropped out of the top 20 after three consecutive years on the list (2019 to 2021).\\n* New to the 2022 list are archway-network/testnets, element-fi/elf-council-frontend, solana-labs/token-list, education/GitHubGraduation-2022, taozhiyu/TyProAction, NixOS/nixpkgs, rust-lang/rust.\\n\\n* Time range: 2022.01.01-2022.09.30, excluding bot events\\n\\n## Who gave the most stars in 2022\\n\\nWe queried the developers who gave the most stars in 2022, took the top 20, and filtered out accounts of suspected bots. If a developer\'s number of star events divided by the number of starred repositories is equal to or greater than 2, we suspect this user to be a bot.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./developers-most-stars.png\').default} width = \\"80%\\" alt=\\"developers-most-stars\\"/>\\n</center>\\n\\n<center><em>Developers who gave the most stars</em></center>\\n\\n<br />\\n\\nWe found that until September 30, 2022, the developer who starred the most repositories had starred a total of 37,228 repositories, an average of 136 repositories per day.\\n\\n\\\\* Time range: 2022.01.01-2022.09.30, excluding bot events\\n\\n## The most active developers since 2011\\n\\nWe queried the top 20 most active developers per year since 2011. This time we didn\'t filter out bot events.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./most-active-developers.png\').default} width = \\"80%\\" alt=\\"most-active-developers\\"/>\\n</center>\\n\\n<center><em>The most active developers</em></center>\\n\\n<br />\\n\\nWe found that the percentage of bots is becoming larger and larger. Bots started to overtake humans in 2013 and have reached over 95% in 2022.\\n\\n## Appendix\\n\\n### Term description\\n\\n* **GitHub events**: GitHub events are triggered by user actions, like starring a repository or pushing code.\\n* **Time range**: In this report, the data collection range of 2022 is from January 1, 2022 to September 30, 2022. When comparing data of 2022 with another year, we use year-on-year analysis.\\n* **Bot events**: Bot-triggered events account for a growing percentage of GitHub events. However, these events are not the focus of this report. We filtered out most of the bot-initiated events by matching regular expressions.\\n\\n### How we classify technical fields by topics\\n\\nWe do exact matching and fuzzy matching based on the repository topic. Exact matching means that the repository topics have a topic that exactly matches the word, and fuzzy matching means that the repository topics have a topic that contains the word.\\n\\n<table>\\n  <tr>\\n   <td><strong>Topic</strong>\\n   </td>\\n   <td><strong>Exact matching</strong>\\n   </td>\\n   <td><strong>Fuzzy matching</strong>\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><strong>GitHub Actions</strong>\\n   </td>\\n   <td>actions\\n   </td>\\n   <td>github-action, gh-action\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><strong>Low Code</strong>\\n   </td>\\n   <td>\\n   </td>\\n   <td>low-code, lowcode, nocode, no-code\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><strong>Web3</strong>\\n   </td>\\n   <td>\\n   </td>\\n   <td>web3\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><strong>Database</strong>\\n   </td>\\n   <td>db\\n   </td>\\n   <td>database, databases\\n<br />\\nnosql, newsql, sql\\n<br />\\nmongodb,neo4j\\n   </td>\\n  </tr>\\n  <tr>\\n   <td><strong>AI</strong>\\n   </td>\\n   <td>ai, aiops, aiot\\n   </td>\\n   <td>artificial-intelligence, machine-intelligence\\n<br />\\ncomputer-vision, image-processing, opencv, computervision, imageprocessing\\n<br />\\nvoice-recognition, speech-recognition, voicerecognition, speechrecognition, speech-processing\\n<br />\\nmachinelearning, machine-learning\\n<br />\\ndeeplearning, deep-learning\\n<br />\\ntransferlearning, transfer-learning\\n<br />\\nmlops\\n<br />\\ntext-to-speech, tts, speech-synthesis, voice-synthesis\\n<br />\\nrobot, robotics\\n<br />\\nsentiment-analysis\\n<br />\\nnatural-language-processing, nlp\\n<br />\\nlanguage-model, text-classification, question-answering, knowledge-graph, knowledge-base\\n<br />\\ngan, gans, generative-adversarial-network, generative-adversarial-networks\\n<br />\\nneural-network, neuralnetwork, neuralnetworks, neural-network, dnn\\n<br />\\ntensorflow\\n<br />\\nPyTorch\\n<br />\\nhuggingface\\n<br />\\ntransformers\\n<br />\\nseq2seq, sequence-to-sequence\\n<br />\\ndata-analysis, data-science\\n<br />\\nobject-detection, objectdetection\\n<br />\\ndata-augmentation\\n<br />\\nclassification\\n<br />\\naction-recognition\\n   </td>\\n  </tr>\\n</table>"},{"id":"/github-data-is-booming","metadata":{"permalink":"/blog/github-data-is-booming","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/github-data-is-booming/index.mdx","source":"@site/blog/github-data-is-booming/index.mdx","title":"GitHub Events Are Booming! Are Bots the Reason?","description":"This post dives deeply into GitHub event trending, why GitHub events are surging, and whether GitHub\'s architecture can handle the increasing load.","date":"2022-08-01T00:00:00.000Z","formattedDate":"August 1, 2022","tags":[{"label":"insight","permalink":"/blog/tags/insight"}],"readingTime":4.105,"hasTruncateMarker":false,"authors":[{"name":"Mia Zhou","title":"Technical Content Developer","url":"https://github.com/luzizhuo","imageURL":"https://github.com/luzizhuo.png","key":"mia"},{"name":"Wink Yao","title":"Head of Community & Developer Ecosystem Team at PingCAP.","url":"https://twitter.com/golangwink","imageURL":"https://github.com/winkyao.png","key":"winkyao"},{"name":"Caitin Chen","title":"Technical Content Developer","url":"https://github.com/CaitinChen","imageURL":"https://github.com/caitinchen.png","key":"caitin"}],"frontMatter":{"title":"GitHub Events Are Booming! Are Bots the Reason?","date":"2022-08-01T00:00:00.000Z","authors":["mia","winkyao","caitin"],"tags":["insight"],"image":"./github-data-is-booming.jpg","description":"This post dives deeply into GitHub event trending, why GitHub events are surging, and whether GitHub\'s architecture can handle the increasing load.","keywords":["github"]},"prevItem":{"title":"Open Source Highlights: Trends and Insights from GitHub 2022","permalink":"/blog/trends-and-insights-from-github-2022"},"nextItem":{"title":"Build a Better GitHub Insight Tool in a Week? A True Story","permalink":"/blog/why-we-choose-tidb-to-support-ossinsight"}},"content":"The [OSS Insight](https://ossinsight.io/) website displays the data changes of GitHub events in real time. GitHub events are activities triggered by user actions on GitHub, for example, commenting and forking a repository. **In nearly seven weeks, GitHub events increased by about 150 million, from 4.7 billion to 4.85 billion.** GitHub events are booming!\\n\\nThis post dives deeply into GitHub event trending, why GitHub events are surging, and whether GitHub\'s architecture can handle the increasing load.\\n\\n## Historical data analysis\\n\\nThe OSS Insight database includes all the GitHub events since 2011. When we plot the number of events by year, we can see that since 2018 they have been increasing rapidly.\\n\\n<br />\\n\\n![GitHub event trending](./github-event-trending.jpg)\\n\\n<center><em>GitHub event trending</em></center>\\n\\n<br />\\n\\nThe figure below shows how long it takes to grow each billion events in GitHub.\\n\\n<br />\\n\\n![The time to reach a billion GitHub events](./github-data-is-booming.jpg)\\n\\n<center><em>The time to reach a billion GitHub events</em></center>\\n\\n<br />\\n\\n**It\'s taking less and less for GitHub to generate 1 billion events. It took more than 6 years for the first billion events and only 13 months for the last billion!**\\n\\n## The secret behind the exponential growth of GitHub events\\n\\n[GitHub Actions](https://github.blog/2018-10-16-future-of-software/) was released in October 2018. Since August 2019, it has [supported continuous integration and continuous delivery (CI/CD)](https://github.blog/2019-08-08-github-actions-now-supports-ci-cd/), and it has been free for open source projects. Therefore, projects hosted on GitHub can automate their own development workflows, and a large number of automation-related bot applications have appeared on GitHub Marketplace. Could GitHub events\' data growth be related to these?\\n\\nTo find the answer, we divided the events into data from humans and data from bots and plotted them with the following histogram. The blue columns represent the human data, and the yellow columns represent the bot data.\\n\\n<br />\\n\\n![Bot events vs. human events](./bot-events-vs-human-events.jpg)\\n\\n<center><em>Bot events vs. human events</em></center>\\n\\n<br />\\n\\nAs you can see, the proportion of GitHub bot events has increased each year. In 2015, they were only 1.23% of all events. In early July of this year, they reached 13.2%. To show the data changes of bot events more clearly, we made the following line chart.\\n\\n<br />\\n\\n![Bot event trending](./bot-event-trending.jpg)\\n\\n<center><em>Bot event trending</em></center>\\n\\n<br />\\n\\nThis figure shows that since 2019, bot events have been grown faster than before. As [Mini256](https://github.com/Mini256), a TiDB community contributor said in [Love, Code, and Robot \u2014 Explore robots in the world of code](https://ossinsight.io/blog/say-thanks-to-github-robots):\\n\\n> For now, rough statistics find that there are more than 95,620 bots on GitHub. The number doesn\'t seem like so much, but wait...\\n\\n> **These 95 thousand bot accounts generated 603 million events. These events account for 12.82% of all public events on GitHub**, and these GitHub robots have served over 18 million open source repositories.\\n\\nBots are playing an increasingly important role on GitHub. Many projects are handing over automated work to bots. We expect that GitHub events will grow faster in the future.\\n\\n## When will GitHub reach 10 billion events?\\n\\nHow many GitHub events will there be by the end of 2022? We fit predictions to GitHub historical data.\\n\\n<br />\\n\\n![Human event fit (left) vs. bot event fit (right)](./human-event-fit-vs-bot-event-fit.jpg)\\n\\n<center><em>Human event fit (left) vs. bot event fit (right)</em></center>\\n\\n<br />\\n\\nIt\'s estimated that by the end of 2022, GitHub events will reach 5.36 billion.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./github-event-prediction.jpg\').default} width = \\"50%\\" alt=\\"github-event-prediction\\"/>\\n</center>\\n\\n<center><em>GitHub event prediction</em></center>\\n\\n<br />\\n\\nAccording to this prediction, GitHub events will exceed 10 billion in February 2025.\\n\\n<br />\\n\\n<center>\\n<img src={require(\'./gitub-events-exceed-10-billion.jpg\').default} width = \\"50%\\" alt=\\"gitub-events-exceed-10-billion\\"/>\\n</center>\\n\\n<center><em>GitHub events will exceed 10 billion in 2025</em></center>\\n\\n<br />\\n\\n## Can MySQL sharding support such a huge amount of data?\\n\\nGitHub uses MySQL as the main storage for all non-git warehouse data. The rapid growth of data volume poses a great challenge to GitHub\'s high availability. In March 2022, GitHub had 3 service disruptions, each lasting 2-5 hours. [The official investigation report](https://github.blog/2022-03-23-an-update-on-recent-service-disruptions/) shows the MySQL database caused the outages. During peak load periods, the GitHub mysql1 database (the main database cluster in GitHub) load increased. Therefore, database access reached the maximum number of connections. This affected the performance of many GitHub services and features.\\n\\nIn fact, over the past few years GitHub has optimized its databases. For example, it added clusters to support platform growth and partitioned the main database. But these improvements did not fundamentally solve the problem. In the near future, GitHub events will exceed 5 billion, or even 10 billion. Can MySQL sharding support such data surge?\\n\\n## Data sources\\n\\nAll the analysis data in this article comes from [OSS Insight](https://ossinsight.io/), a tool based on [TiDB]( https://www.pingcap.com/tidb-serverless/?utm_source=ossinsight&utm_medium=referral) to analyze and gain insights into GitHub events data.\\n\\nYou can use it to easily get insights about developers and repositories based on billions of GitHub events. You can also get the latest and historical rankings and trends in technical fields.\\n\\n<br />\\n\\n![The OSS Insight website](./oss-insight-website.png)\\n\\n<center><em>The OSS Insight website</em></center>\\n\\n<br />"},{"id":"/why-we-choose-tidb-to-support-ossinsight","metadata":{"permalink":"/blog/why-we-choose-tidb-to-support-ossinsight","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/why-we-choose-tidb-to-support-ossinsight/index.mdx","source":"@site/blog/why-we-choose-tidb-to-support-ossinsight/index.mdx","title":"Build a Better GitHub Insight Tool in a Week? A True Story","description":"The story about how we build the ossinsight project, including how we deal with the historical and real-time huge data, the database solutions and so on.","date":"2022-06-20T00:00:00.000Z","formattedDate":"June 20, 2022","tags":[{"label":"tidb","permalink":"/blog/tags/tidb"}],"readingTime":9.47,"hasTruncateMarker":false,"authors":[{"name":"Wink Yao","title":"Head of Community & Developer Ecosystem Team at PingCAP.","url":"https://twitter.com/golangwink","imageURL":"https://github.com/winkyao.png","key":"winkyao"},{"name":"Fendy Feng","title":"Technical Content Developer","url":"https://github.com/septemberfd","imageURL":"https://github.com/septemberfd.png","key":"fendy"}],"frontMatter":{"title":"Build a Better GitHub Insight Tool in a Week? A True Story","date":"2022-06-20T00:00:00.000Z","authors":["winkyao","fendy"],"tags":["tidb"],"image":"./how-different-db-handle-github-data.png","description":"The story about how we build the ossinsight project, including how we deal with the historical and real-time huge data, the database solutions and so on.","keywords":["tidb","ranking","github","database","github archive","gitHub metrics"]},"prevItem":{"title":"GitHub Events Are Booming! Are Bots the Reason?","permalink":"/blog/github-data-is-booming"},"nextItem":{"title":"Love, Code, and Robot \u2014 Explore robots in the world of code","permalink":"/blog/say-thanks-to-github-robots"}},"content":"In early January 2022, [Max](https://twitter.com/ngaut1), our CEO, a big fan of open-source, asked if my team could build a small tool to help us understand all the open-source projects on GitHub; and, that if everything worked well, we should open the API to help open source developers to build better insights. In fact, GitHub continuously publishes the public events in its open-source world through the open API. (Thank you and well done! Github). We can certainly learn a lot from the data!  \\n\\nI was excited about this project until Max said: \u201cYou\u2019ve only got one week.\u201d Well, the boss is the boss! Although time was tight and we were faced with multiple head-aching problems, I decided to take up this challenge. \\n\\n\\n## Headache 1: we need both historical and real-time data.\\n\\nAfter some quick research, we found [GHArchive](https://www.gharchive.org/), an open-source project that collects and archives all GitHub data from 2011 and updates it hourly. By the way, a lot of open-source analytical tools such as CNCF\'s [Devstats](https://github.com/cncf/devstats) rely on GH Archive, too. \\n\\n**Thanks to GH Archive, we found the data source.**\\n\\nBut there\'s another problem: hourly data is good, but not good enough. We wanted our data to be updated in real time\u2014or at least near real time. We decided to directly use the [GitHub event API](https://docs.github.com/en/rest/activity/events), which collects all events that have occurred within the past hour. \\n\\nBy combining the data from the GH Archive and the GitHub event API, we can gain streaming, real-time event updates.\\n\\n\\n<br />\\n\\n![GitHub event updates](./github-events-updates.gif)\\n\\n<center><em>GitHub event updates</em></center>\\n\\n<br />\\n\\n\\n## Headache 2: the data is huge!\\n\\nAfter we decompressed all the data from GH Archive, we found there were more than 4.6 billion rows of GitHub events. That\u2019s a lot of data!  We also noticed that about 300,000 rows were generated and updated each hour.\\n\\n<br />\\n\\n![The data volume of GitHub events occurred after 2011](./github-events.png)\\n\\n<center><em>The data volume of GitHub events occurred after 2011</em></center>\\n\\n<br />\\n\\nThe database solution would be tricky here. Our goal is to build an application that provides real-time data insights based on a continuously growing dataset. So, scalability is a must. NoSQL databases can provide good scalability, but what follows is how to handle complex analytical queries. Unfortunately, NoSQL databases are not good at that. \\n\\n<br />\\n\\n<center>\\n  <img width=\\"50%\\" src={require(\'@site/blog/why-we-choose-tidb-to-support-ossinsight/scalability-SQL.jpg\').default} alt=\'Scalability vs SQL\' />\\n</center>\\n\\n<br />\\n\\nAnother option is to use an OLAP database such as ClickHouse. ClickHouse can handle the analytical workload very well, but it is not designed for serving online traffic. If we chose it, we would need another database for the online traffic. \\n\\n<br />\\n\\n<center>\\n  <img width=\\"50%\\" src={require(\'@site/blog/why-we-choose-tidb-to-support-ossinsight/olap-onlineserving.jpg\').default} alt=\'OLAP vs Online Serving\' />\\n</center>\\n\\n<br />\\n\\nWhat about sharding the database and then building an extract, transform, load (ETL) pipeline to synchronize the new events to a data warehouse? This sounds workable.\\n\\n<br />\\n\\n![How a RDBMS handles the GitHub data](./sharded-architecture.png)\\n\\n<center><em>How a RDBMS handles the GitHub data</em></center>\\n\\n<br />\\n\\nAccording to our product manager\'s (PM\u2019s) plan, we needed to do some repo-specific or user-specific analysis. Although the total data volume was huge, the number of events was not too large for a single project or user. This meant using the secondary indexes in RDBMS would be a good idea. But, if we decided to use the above architecture, we had to be careful in selecting the database sharding key. For example, if we use `user_id` as the sharding key, then queries based on `repo_id` will be very tricky. \\n\\nAnother requirement from the PM was that our insight tool should provide OpenAPI, which meant we would have unpredictable concurrent traffic from the outside world. \\n\\nSince we\'re not experts on Kafka and data warehouses, mastering and building such an infrastructure in just one week was a very difficult task for us.\\n\\nThe choice is obvious now, and don\'t forget PingCAP is a database company! TiDB seems a perfect fit for this, and it\'s a good chance to eat our own dog food. So, why not using TiDB! :) \\n \\n\\n**If we use TiDB, can we get:**\\n- SQL support, including complex & flexible queries? \u2611\ufe0f \\n- Scalability?  \u2611\ufe0f \\n- Secondary index support for fast lookup? \u2611\ufe0f \\n- Capability for online serving? \u2611\ufe0f \\n\\nWow! It seems we got a winner! \\n\\n<br />\\n\\n![By using the secondary index, TiDB scanned 29,639 rows (instead of 4.6 billion rows) GitHub events in 4.9 ms](./tidb-scanned-kennytm.png)\\n\\n<center><em>By using the secondary index, TiDB scanned 29,639 rows (instead of 4.6 billion rows) GitHub events in 4.9 ms</em></center>\\n\\n<br />\\n\\n\\n**To choose a database to support an application like OSS Insight, we think TiDB is a great choice.** Plus, its simplified technology stack means a faster go-to-market and faster delivery of my boss\' assignment. \\n\\nAfter we used TiDB, we got a simplified architecture as shown below. \\n\\n<br />\\n\\n![Simplified architecture after we use TiDB](./how-different-db-handle-github-data.png)\\n\\n<center><em>Simplified architecture after we use TiDB</em></center>\\n\\n<br />\\n\\n## Headache 3: We have a \\"pushy\\" PM!\\n\\nJust as the subtitle indicates, we have a very \u201cpushy\u201d PM, which is not always a bad thing. :)  His demands kept extending, from the single project analysis at the very beginning to the comparison and ranking of multiple repositories, and to other multidimensional analysis such as the geographical distribution of stargazers and contributors. What\u2019s more pressing was that the deadlines stayed unchanged!!! \\n\\n**We had to keep a balance between the growing demands and the tight deadlines.**\\n\\nTo save time, we built our website using [Docusaurus](https://github.com/facebook/docusaurus), an open source static site generator in React with scalability, rather than building a site from scratch. We also used [Apache Echarts](https://github.com/apache/echarts), a powerful charting library, to turn analytical results into good-looking and easy-to-understand charts. \\n\\nWe chose TiDB as the database to support our website, and it perfectly supports SQL. This way, our back-end engineers could write SQL commands to handle complex and flexible analytical queries with ease and efficiency. Then, our front-end engineers would just need to display those SQL execution results in the form of good-looking charts. \\n\\nFinally, we made it. We prototyped our tool in just one week, and named it [OSS Insight](https://ossinsight.io/), short for open source software insights. We continued to fine-tune it, and it was [officially released](https://ossinsight.io/blog/explore-deep-in-4.6-billion-github-events/) on May 3. \\n\\n## How we deal with analytical queries with SQL\\n\\nLet\'s use one example to show you how we deal with complex analytical queries. \\n\\n### Analyze a GitHub collection: JavaScript frameworks\\n\\n[OSS Insight](https://ossinsight.io/) can analyze popular GitHub collections by many metrics including the number of stars, issues, and contributors. Let\u2019s identify which JavaScript framework has the most issue creators. \\nThis is an analytical query that includes aggregation and ranking. To get the result, we only need to execute one SQL statement: \\n\\n```sql\\nSELECT\\n   ci.repo_name  AS repo_name,\\n   COUNT(distinct actor_login) AS num\\nFROM\\n   github_events ge\\n   JOIN collection_items ci ON ge.repo_id = ci.repo_id\\n   JOIN collections c ON ci.collection_id = c.id\\nWHERE\\n   type = \'IssuesEvent\'\\n   AND action = \'opened\'\\n   AND c.id = 10005\\n   -- Exclude Bots\\n   and actor_login not like \'%bot%\'\\n   and actor_login not in (select login from blacklist_users)\\nGROUP BY 1\\nORDER BY 2 DESC\\n;\\n```\\n\\nIn the statement above, the `collections` and `collection_items` tables store the data of all GitHub repository collections in various areas. Each table has 30 rows. To get the order of issue creators, we need to associate the repository ID in the `collection_items` table with the real, 4.6-billion-row `github_events` table as shown below. \\n\\n\\n```\\n\\nmysql> select * from collection_items where collection_id = 10005;\\n+-----+---------------+-----------------------+-----------+\\n| id  | collection_id | repo_name             | repo_id   |\\n+-----+---------------+-----------------------+-----------+\\n| 127 | 10005         | marko-js/marko        | 15720445  |\\n| 129 | 10005         | angular/angular       | 24195339  |\\n| 131 | 10005         | emberjs/ember.js      | 1801829   |\\n| 135 | 10005         | vuejs/vue             | 11730342  |\\n| 136 | 10005         | vuejs/core            | 137078487 |\\n| 138 | 10005         | facebook/react        | 10270250  |\\n| 142 | 10005         | jashkenas/backbone    | 952189    |\\n| 143 | 10005         | dojo/dojo             | 10160528  |\\n...\\n30 rows in set (0.05 sec)\\n\\n```\\n\\nNext, let\'s look at the execution plan. TiDB is compatible with MySQL syntax, so its execution plan looks very similar to that of MySQL.\\n\\nIn the figure below, notice the parts in red boxes. The data in the table `collection_items` is read through `distributed[row]`, which means this data is processed by TiDB\u2019s row storage engine, TiKV. The data in the table `github_events` is read through `distributed[column]`, which means this data is processed by TiDB\u2019s columnar storage engine, TiFlash. TiDB uses both row and columnar storage engines to execute the same SQL statement. This is so convenient for OSS Insight because it doesn\u2019t have to split the query into two statements. \\n\\n<br />\\n\\n![TiDB execution plan](./tidb-execution-plan-2.png)\\n\\n<center><em>TiDB execution plan</em></center>\\n\\n<br />\\n\\n\\nTiDB returns the following result: \\n\\n```\\n+-----------------------+-------+\\n| repo_name             | num   |\\n+-----------------------+-------+\\n| angular/angular       | 11597 |\\n| facebook/react        | 7653  |\\n| vuejs/vue             | 6033  |\\n| angular/angular.js    | 5624  |\\n| emberjs/ember.js      | 2489  |\\n| sveltejs/svelte       | 1978  |\\n| vuejs/core            | 1792  |\\n| Polymer/polymer       | 1785  |\\n| jquery/jquery         | 1587  |\\n| jashkenas/backbone    | 1463  |\\n| ionic-team/stencil    | 1101  |\\n...\\n30 rows in set\\nTime: 7.809s\\n\\n``` \\n\\nThen, we just need to draw [the result](https://ossinsight.io/blog/deep-insight-into-js-framework-2021/#which-javascript-framework-have-the-widest-feedback-sources) with Apache Echarts into a more visualized chart as shown below. \\n\\n<br />\\n\\n![JavaScript frameworks with the most issue creators](./javascript-framework-rankings.png)\\n\\n<center><em>JavaScript frameworks with the most issue creators</em></center>\\n\\n<br />\\n\\n\\nNote: You can click the `REQUEST INFO` on the upper right side of each chart to get the SQL command for each result. \\n\\n## Feedback: People love it!\\n\\nAfter we released OSS Insight on May 3, we have received loud applause on social media, via emails and private messages, from many developers, engineers, researchers, and people who are passionate about the open source community in various companies and industries. \\n\\nI am more than excited and grateful that so many people find OSS Insight interesting, helpful, and valuable. I am also proud that my team made such a wonderful product in such a short time. \\n\\n<br />\\n\\n![Applause given by developers and organizations on Twitter-1](./twitter-1.png)\\n\\n![Applause given by developers and organizations on Twitter-1](./twitter-2.jpg)\\n\\n<center><em>Applause given by developers and organizations on Twitter</em></center>\\n\\n<br />\\n\\n\\n## Lessons learned \\n\\nLooking back at the process we used to build this website, we have learned many mind-refreshing lessons.\\n\\n**First, quick doesn\u2019t mean dirty, as long as we make the right choices.** Building an insight tool in just one week is tricky, but thanks to those wonderful, ready-made, and open source projects such as TiDB, Docusaurus, and Echarts, we made it happen with efficiency and without compromising the quality.  \\n\\n**Second, it\u2019s crucial to select the right database\u2014especially one that supports SQL.** TiDB is a distributed SQL database with great scalability that can handle both transactional and real-time analytical workloads. With its help, we can process billions of rows of data with ease, and use SQL commands to execute complicated real-time queries. Further, using TiDB means we can leverage its resources to go to market faster and get feedback promptly.  \\n\\nIf you like our project or are interested in joining us, you\u2019re welcome to **[submit your PRs](https://github.com/pingcap/ossinsight)** to our GitHub repository. You can also follow us on [Twitter](https://twitter.com/OSSInsight) for the latest information. \\n\\n\\n:::note\\n\\n### \ud83d\udccc Join our workshop\\n\\nIf you want to get your own insights, you can [join our workshop](https://share.hsforms.com/1E-qtGQWrTVmctP8kBT34gw2npzm) and try using TiDB to support your own datasets. \\n\\n:::"},{"id":"/say-thanks-to-github-robots","metadata":{"permalink":"/blog/say-thanks-to-github-robots","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/say-thanks-to-github-robots/index.mdx","source":"@site/blog/say-thanks-to-github-robots/index.mdx","title":"Love, Code, and Robot \u2014 Explore robots in the world of code","description":"This article describes the evolution of bots in the GitHub world, their behaviors and characteristics, and the impact they have brought to the open source world.","date":"2022-05-12T00:00:00.000Z","formattedDate":"May 12, 2022","tags":[],"readingTime":6.285,"hasTruncateMarker":true,"authors":[{"name":"Mini256","title":"Engineer of TiDB Community","url":"https://github.com/Mini256","imageURL":"https://github.com/Mini256.png","key":"Mini256"}],"frontMatter":{"title":"Love, Code, and Robot \u2014 Explore robots in the world of code","date":"2022-05-12T00:00:00.000Z","authors":["Mini256"],"image":"./love-code-robots-cover.png","description":"This article describes the evolution of bots in the GitHub world, their behaviors and characteristics, and the impact they have brought to the open source world.","keywords":["GitHub Bots","GitHub APP","TiDB","Database","Stale Bots","GitHub Archive","GitHub Metrics","Automation"]},"prevItem":{"title":"Build a Better GitHub Insight Tool in a Week? A True Story","permalink":"/blog/why-we-choose-tidb-to-support-ossinsight"},"nextItem":{"title":"Deep Insights into JavaScript Frameworks","permalink":"/blog/deep-insight-into-js-framework-2021"}},"content":"import {CommonChart} from \\"../../src/components/CommonChart\\";\\n\\n\\nWhen it comes to GitHub, we often see fake GitHub users who are always enthusiastic and active, giving timely feedback to project maintainers and contributors, and helping developers with tasks that can be automated. Yes, the next thing I want to discuss is something about GitHub bots.\\n\\n## Overview\\n\\nIn the [OSSInsight](https://ossinsight.io/) project, we have developed a number of metrics to provide insight into open source projects. When developing some open source project metrics, we always consider excluding bot-generated actions or events from the metric calculation. \\n\\nHowever, We can\'t ignore the contribution of robots in the domain of open source, and it\'s important to shift our thinking to look at what bots are doing on GitHub.\\n\\nGitHub\'s bots help developers do a lot of work:\\n\\n- Issue triage and management. (For example: `stale[bot]`\u3001`todo[bot]`)\\n- Code review, security audit and quality inspection (For example, `snyk-bot`).\\n- Format checking like ensuring license agreement signing, or make sure  commit messages semantic. (For example: `CLAassistant`)\\n- Integration with third-party systems, including Jira, Slack, Jenkins and so on.\\n- As an agent to help contributor perform some operations needed permission on the repository. (For example: `k8s-ci-bot`\u3001`ti-chi-bot`)\\n\\n## History trends\\n\\nLooking at the historical data, we see that the number of GitHub bots grows significantly faster after 2019 (on average, 20,000 new bots are created each year)\\n\\n<CommonChart\\n  chart=\'dynamic-line\'\\n  query=\'archive/bot/cumulative-numbers\'\\n  formatSql={false}\\n  xIndex=\\"event_year\\"\\n  yIndex=\\"bots_total\\"\\n/>\\n\\n\x3c!--truncate--\x3e\\n\\nI looked into what happened during the year and found that GitHub invested a lot in its software development infrastructure (including bots) during the year.\\n\\n- On May 23, 2019, GitHub announced acquired Dependabot (Aka, `dependabot[bot]`).\\n\\n- In June 17th, 2019, [GitHub announced acquired Pull Panda](https://github.blog/2019-06-17-github-acquires-pull-panda/).\\n\\n- In September 18th, 2019, [GitHub announced acquired Semmle](https://github.blog/2019-09-18-github-welcomes-semmle/) (Aka, the team built `lgtm-com[bot]`).\\n\\nAt this year, we, human beings, were amazed to discover that bots could find problems, submit PRs, wait CI test code, complete merges and comment on PRs on their own without any human involvement.\\n\\n[![Bot automatically completes a pull request](./bot_automatically_completes_a_pull_request.png)](https://github.com/buildo/react-components/pull/1367)\\n\\nFor now, rough statistics found that there are more than 95,620 bots on GitHub, the number doesn\'t seem like so much, but wait...\\n\\n<details>\\n<summary>Click here to show computational process</summary>\\n\\nBefore that, we had collected 4.7 billion github events stored in our database. Now we can count the number of bots on GitHub by executing a simple SQL statement:\\n\\n```sql\\nSELECT COUNT(DISTINCT actor_login) AS \'Bots\'\\nFROM github_events ge\\nWHERE actor_login REGEXP \'^(bot-.+|.+bot|.+\\\\\\\\[bot\\\\\\\\]|.+-bot-.+|robot-.+|.+-ci-.+|.+-ci|.+-testing|.+clabot.+|.+-gerrit|k8s-.+|.+-machine|.+-automation|github-.+|.+-github|.+-service|.+-builds|codecov-.+|.+teamcity.+|jenkins-.+|.+-jira-.+)$\';\\n```\\n\\nIn this SQL statement, we use a regular expression to determine which `actor_login` is the robot login. For example, the well known star robot `dependabot[bot]`, whose github login ends with `[bot]`, we can find more bots among a large number of events based on this method.\\n\\n```\\n+-------+\\n| Bots  |\\n+-------+\\n| 95620 |\\n+-------+\\n1 row in set\\nTime: 16.921s\\n```\\n\\n</details>\\n\\n**\ud83d\udc40 These 95 thousand bot accounts generated 603 million events, these events account for 12.82% of all public events on GitHub.**\\n\\n<details>\\n<summary>Click here to show computational process</summary>\\n\\n1. Count the total number of public events triggered by GitHub bot\\n\\n```sql\\nSELECT COUNT(*) AS \'Bot\'\'s events\'\\nFROM github_events ge\\nWHERE actor_login REGEXP \'^(bot-.+|.+bot|.+\\\\\\\\[bot\\\\\\\\]|.+-bot-.+|robot-.+|.+-ci-.+|.+-ci|.+-testing|.+clabot.+|.+-gerrit|k8s-.+|.+-machine|.+-automation|github-.+|.+-github|.+-service|.+-builds|codecov-.+|.+teamcity.+|jenkins-.+|.+-jira-.+)$\';\\n```\\n\\n```\\n+--------------+\\n| Bot\'s events |\\n+--------------+\\n| 603554237    |\\n+--------------+\\n1 row in set\\nTime: 13.087s\\n```\\n\\n2. Count the total number of all public events on GitHub\\n\\n```sql\\nSELECT COUNT(*) AS \'All public events\' FROM github_events ge;\\n```\\n\\n```\\n+-------------------+\\n| All public events |\\n+-------------------+\\n| 4705191048        |\\n+-------------------+\\n1 row in set\\nTime: 4.322s\\n```\\n\\n3. Calculate the proportion of the former in the latter\\n\\n```sql\\nSELECT CONCAT(TRUNCATE(603554237 / 4705191048 * 100, 2), \'%\') AS \'Proportion of Events\';\\n```\\n\\n```\\n+----------------------+\\n| Proportion of Events |\\n+----------------------+\\n| 12.82%               |\\n+----------------------+\\n1 row in set\\nTime: 0.047s\\n```\\n\\n\\n</details>\\n\\nAnd these GitHub robots have served over 18 million open source repositories.\\n\\n<details>\\n<summary>Click here to show computational process</summary>\\n\\n```sql\\nSELECT COUNT(DISTINCT repo_id) AS \'Repositories\'\\nFROM github_events ge\\nWHERE actor_login REGEXP \'^(bot-.+|.+bot|.+\\\\\\\\[bot\\\\\\\\]|.+-bot-.+|robot-.+|.+-ci-.+|.+-ci|.+-testing|.+clabot.+|.+-gerrit|k8s-.+|.+-machine|.+-automation|github-.+|.+-github|.+-service|.+-builds|codecov-.+|.+teamcity.+|jenkins-.+|.+-jira-.+)$\';\\n```\\n\\n```\\n+--------------+\\n| Repositories |\\n+--------------+\\n| 18415262     |\\n+--------------+\\n1 row in set\\nTime: 27.060s\\n```\\n\\n</details>\\n\\n## Cases study\\n\\n### Dependabot\\\\[bot\\\\]\\n\\n`dependabot[bot]` is a hard-working bot responsible for helping open source projects keep their dependencies up to date.\\n\\nBy analyzing depentenbot\'s Push commit time, we found that he likes to start his busy week at 8:00 on Mondays (at GMT timezone).\\n\\n<CommonChart\\n  chart=\'heatmapchart\'\\n  category=\'archive/bot/dependabot-commits-time-distribution\'\\n  xIndex=\'hour\'\\n  yIndex=\'dayofweek\'\\n  valueIndex=\'pushes\'\\n  formatSql={false}\\n/>\\n\\nIt is commendable that, after a series of log4j security vulnerabilities came to light, it helped many Java-language repositories to update the dependency to a secure version timely.\\n\\n### Stale Bots\\n\\nStale Bot is a controversial class of robots, they are responsible for reminding maintainers to continue promoting long-term stale issue.\\n\\n<table>\\n<tr>\\n    <th>Bad practice</th>\\n    <th>Best practices</th>\\n</tr>\\n<tr>\\n<td>\\n\\nThe user from Gatsby:\\n\\n> I used to open GitHub issues to Gatsby to report bugs. Almost nothing was ever fixed and every few weeks I had to manually clickety-click to keep the issues alive because of the stale bot. Guess what I do now? I don\'t report bugs to Gatsby, and I recommend against using Gatsby in newer projects.\\n\\n</td>\\n<td>\\n\\nThe user from NixOS:\\n\\n> IMO NixOS has the right stalebot settings <sub>[0]</sub>. It was discussed thoroughly in the RFC, as to choose the right information text and other actions by the bot. For example, the bot will only mark the issue/PR as stale and will never close the issue or lock it. Issues are only ever closed by humans.\\nThe information text they came up with is quite a bit longer than the ansible one <sub>[1]</sub>. I think this is a very important point when adding such a bot, otherwise the user will be left helpless.\\n\\n> [0]: https://github.com/NixOS/rfcs/pull/51\\n\\n> [1]: https://github.com/NixOS/nixpkgs/pull/92254\\n\\n</td>\\n</tr>\\n</table>\\n\\nTo verify the above statement, we run the following query through the SQL statement:\\n\\n```sql\\nSELECT actor_login, COUNT(DISTINCT pr_or_issue_id) AS cnt\\nFROM github_events ge\\nWHERE\\n    repo_name = \'gatsbyjs/gatsby\'\\n    AND type = \'IssuesEvent\'\\n    AND action = \'closed\'\\n    AND (actor_login LIKE \'%[bot]\' OR actor_login LIKE \'%bot\')\\nGROUP BY actor_login\\nORDER BY cnt DESC;\\n```\\n\\nWe know from the following query that many Issues in the `gatsbyjs/gatsby` repository have been closed by the stale bots.\\n\\n```\\n+---------------------+------+\\n| actor_login         | cnt  |\\n+---------------------+------+\\n| gatsbot[bot]        | 1389 |\\n| github-actions[bot] | 777  |\\n| gatsbybot           | 265  |\\n| stale[bot]          | 50   |\\n| renovate[bot]       | 1    |\\n+---------------------+------+\\n5 rows in set\\nTime: 0.100s\\n```\\n\\nI think it is necessary to distinguish between what should be done by robots and what must be done with human involvement.\\n\\n### Weird bots\\n\\nThere are some weird bots on GitHub that don\'t help people work and learn on GitHub, but rather act as data movers.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/bot/weird-bots-ranking\'\\n  formatSql={false}\\n  categoryIndex=\'actor_login\'\\n  valueIndex=\'contributions\'\\n  categoryType=\'owner\'\\n  seriesName=\'Contributions\'\\n/>\\n\\n- Some of them will use GitHub as a free place to archive their data, for example, `speedtracker-bot`, `newstools`.\\n\\n- Some of them will periodically upload a timestamp to the code repository as a commit, for example, `keihin00174`.\\n\\n- Some are even crazier, and you can\'t even access their profile pages because the number of events generated is so large that GitHub\'s database can\'t process them quickly, for example, `mhutchinson-witness`, `direwolf-github`.\\n\\n    ![Too long time to load bot profile](too_long_time_to_load_profile.png)\\n\\n## Ranks\\n\\nWe ranked the robots according to their contribution.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/bot/contribution-ranking\'\\n  formatSql={false}\\n  categoryIndex=\'actor_login\'\\n  valueIndex=\'contributions\'\\n  categoryType=\'owner\'\\n  seriesName=\'Contributions\'\\n/>\\n\\n## Recommended reading\\n\\n- [GitHub Stale Bots: A False Economy](https://blog.benwinding.com/github-stale-bots/)\\n- [One million Dependabot pull requests merged](https://github.blog/2019-07-25-one-million-dependabot-pull-requests-merged/)\\n- [Pull Panda is shutting down](https://github.blog/changelog/2022-03-23-pull-panda-is-shutting-down/)\\n- [Best bots to improve your software development process](https://livablesoftware.com/best-bots-software-development/)"},{"id":"/deep-insight-into-js-framework-2021","metadata":{"permalink":"/blog/deep-insight-into-js-framework-2021","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/deep-insight-into-js-framework-2021/index.mdx","source":"@site/blog/deep-insight-into-js-framework-2021/index.mdx","title":"Deep Insights into JavaScript Frameworks","description":"In this chapter, we will share with you some of the top JavaScript Framework repos(JSF repos) on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on.","date":"2022-05-03T00:00:00.000Z","formattedDate":"May 3, 2022","tags":[{"label":"insight","permalink":"/blog/tags/insight"}],"readingTime":2.23,"hasTruncateMarker":true,"authors":[{"name":"Jagger","title":"Engineer of TiDB Community","url":"https://github.com/634750802","imageURL":"https://github.com/634750802.png","key":"Jagger"}],"frontMatter":{"title":"Deep Insights into JavaScript Frameworks","date":"2022-05-03T00:00:00.000Z","authors":["Jagger"],"tags":["insight"],"image":"./jsframework.png","description":"In this chapter, we will share with you some of the top JavaScript Framework repos(JSF repos) on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on.","keywords":["JavaScript Framework repos","tidb","top ranking","github","database","github archive","gitHub metrics"]},"prevItem":{"title":"Love, Code, and Robot \u2014 Explore robots in the world of code","permalink":"/blog/say-thanks-to-github-robots"},"nextItem":{"title":"Deep Insights into Low-code Development Tools","permalink":"/blog/deep-insight-into-lowcode-development-tools-2021"}},"content":"import {CommonChart} from \\"../../src/components/CommonChart\\";\\n\\nIn this chapter, we will share with you some of **the top JavaScript Framework repos(JSF repos) on GitHub in 2021** measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on. \\n\\nNote: \\n1. You can move your cursor onto any of the repository bars/lines on the chart and get the exact number. \\n2. The SQL commands above each chart are what we use on our TiDB Cloud to get the analytical results. Try those SQL commands by yourselves on TiDB Cloud with this [10-minute tutorial](/blog/try-it-yourself/).\\n\\n\\n## Star history of top JavaScript Framework repos since 2011\\n\\nThe number of stars is often thought of as a measure of whether a GitHub repository is popular or not. We sort all JavaScript framework repositories from GitHub by the total number of historical stars since 2011. For visualizing the results more intuitively, we show the top 10 open source databases by using an interactive line chart.\\n\\n<CommonChart\\n    chart=\'dynamic-stars\'\\n    category=\'archive/2021/repo-racing-by-stars\'\\n    formatSql={false}\\n    field=\'js_framework\'\\n/>\\n\\n\x3c!--truncate--\x3e\\n\\n## Top 10 most starred JSF repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-stars-growth\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'stars\'\\n    seriesName=\'Stars\'\\n    field=\'js_framework\'\\n    n={10}\\n/>\\n\\n## Top 10 JSF repos with the most PRs in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'prs\'\\n    seriesName=\'PRs\'\\n    field=\'js_framework\'\\n    n={10}\\n/>\\n\\n## Which javascript framework have the widest feedback sources?\\n\\nThe chart below displays the number of issue creators of leading javascript framework each year and their growth trend during the past ten years.\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-issue-creators\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'issue_creators\'\\n    seriesName=\'Issue Creators\'\\n    categoryType={false}\\n    field=\'js_framework\'\\n    n={10}\\n/>\\n\\n## Top 20 developers contributing the most PRs to JSF repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-pr-creator-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'actor_login\'\\n    valueIndex=\'prs\'\\n    categoryType=\'owner\'\\n    seriesName=\'PRs\'\\n    field=\'js_framework\'\\n    n={20}\\n/>\\n\\n## Top 10 JSF repos with the highest YoY growth rate of stars in 2021\\n\\n<CommonChart\\n  chart=\'yoychart\'\\n  category=\'archive/2021/repo-ranking-by-yoy-stars-growth\'\\n  formatSql={false}\\n  field=\'js_framework\'\\n/>\\n\\n## Top 10 JSF repos with the lowest YoY growth rate of stars in 2021\\n\\n<CommonChart\\n    chart=\'yoychart\'\\n    category=\'archive/2021/repo-ranking-by-yoy-stars-growth-least\'\\n    formatSql={false}\\n    field=\'js_framework\'\\n/>\\n\\n## Top 10 most used programming languages in JSF repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/language-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'language\'\\n    valueIndex=\'prs\'\\n    categoryType=\'lang\'\\n    seriesName=\'PRs\'\\n    field=\'js_framework\'\\n/>\\n\\n## Top 20 companies contributing the most to JSF repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/company-ranking-by-contributions\'\\n    formatSql={false}\\n    categoryIndex=\'company\'\\n    valueIndex=\'contributions\'\\n    seriesName=\'Contributions\'\\n    categoryType={false}\\n    field=\'js_framework\'\\n    n={20}\\n/>\\n\\n## Top 10 countries/regions contributing the most to JSF repos in 2021\\n\\n<CommonChart\\n    chart=\'worldmapchart\'\\n    category=\'archive/2021/country-ranking-by-contributions\'\\n    formatSql={false}\\n    categoryIndex=\'country_code\'\\n    valueIndex=\'contributions\'\\n    seriesName=\'Contributions\'\\n    field=\'js_framework\'\\n    n={10}\\n/>\\n\\n## The Rankings of JSF repos measured by Z-score in 2021\\n\\nThe analytical results displayed above are generated based on just one single metric of these three: stars, PRs, or contributors. Now, we will use the [Z-score](https://en.wikipedia.org/wiki/Standard_score) method to rank the JSF repos on GitHub.\\n\\nThis is the comprehensive ranking calculated by z-score:\\n\\n<CommonChart\\n    chart=\'zscorechart\'\\n    category=\'archive/2021/repo-ranking-by-z-score\'\\n    formatSql={false}\\n    field=\'js_framework\'\\n    n={50}\\n/>"},{"id":"/deep-insight-into-lowcode-development-tools-2021","metadata":{"permalink":"/blog/deep-insight-into-lowcode-development-tools-2021","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/deep-insight-into-lowcode-development-tools-2021/index.mdx","source":"@site/blog/deep-insight-into-lowcode-development-tools-2021/index.mdx","title":"Deep Insights into Low-code Development Tools","description":"In this chapter, we will share with you some of the top low-code development tools repos (LCDT repos) on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on.","date":"2022-05-03T00:00:00.000Z","formattedDate":"May 3, 2022","tags":[{"label":"insight","permalink":"/blog/tags/insight"}],"readingTime":1.71,"hasTruncateMarker":true,"authors":[{"name":"Jagger","title":"Engineer of TiDB Community","url":"https://github.com/634750802","imageURL":"https://github.com/634750802.png","key":"Jagger"}],"frontMatter":{"title":"Deep Insights into Low-code Development Tools","date":"2022-05-03T00:00:00.000Z","authors":["Jagger"],"tags":["insight"],"image":"./lowcode.png","description":"In this chapter, we will share with you some of the top low-code development tools repos (LCDT repos) on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on.","keywords":["low-code","tidb","top ranking","github","database","github archive","gitHub metrics"]},"prevItem":{"title":"Deep Insights into JavaScript Frameworks","permalink":"/blog/deep-insight-into-js-framework-2021"},"nextItem":{"title":"Deep Insight Into Open Source Databases","permalink":"/blog/deep-insight-into-open-source-databases"}},"content":"import {CommonChart} from \\"../../src/components/CommonChart\\";\\n\\nIn this chapter, we will share with you some of the **top low-code development tools repos (LCDT repos)** on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on. \\n\\n\x3c!--truncate--\x3e\\n\\nNote: \\n1. You can move your cursor onto any of the repository bars/lines on the chart and get the exact number. \\n2. The SQL commands above each chart are what we use on our TiDB Cloud to get the analytical results. Try those SQL commands by yourselves on TiDB Cloud with this [10-minute tutorial](/blog/try-it-yourself/).\\n\\n## Star history of top LCDT repos since 2011\\n\\n<CommonChart\\n    chart=\'dynamic-stars\'\\n    category=\'archive/2021/repo-racing-by-stars\'\\n    formatSql={false}\\n    field=\'nocode\'\\n/>\\n\\n## Top 10 most starred LCDT repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-stars-growth\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'stars\'\\n    seriesName=\'Stars\'\\n    field=\'nocode\'\\n    n={10}\\n/>\\n\\n\\n## Top 10 LCDT repos with the most PRs in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'prs\'\\n    seriesName=\'PRs\'\\n    field=\'nocode\'\\n    n={10}\\n/>\\n\\n## Top 20 developers contributing the most PRs to LCDT repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-pr-creator-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'actor_login\'\\n    valueIndex=\'prs\'\\n    categoryType=\'owner\'\\n    seriesName=\'PRs\'\\n    field=\'nocode\'\\n    n={20}\\n/>\\n\\n## Top 10 LCDT repos with the highest YoY growth rate in 2021\\n\\n<CommonChart\\n    chart=\'yoychart\'\\n    category=\'archive/2021/repo-ranking-by-yoy-stars-growth\'\\n    formatSql={false}\\n    field=\'nocode\'\\n/>\\n\\n## Top 10 LCDT repos with the lowest YoY growth rate in 2021\\n\\n<CommonChart\\n    chart=\'yoychart\'\\n    category=\'archive/2021/repo-ranking-by-yoy-stars-growth-least\'\\n    formatSql={false}\\n    field=\'nocode\'\\n/>\\n\\n## Top 7 most used programming languages in LCDT repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/language-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'language\'\\n    valueIndex=\'prs\'\\n    categoryType=\'lang\'\\n    seriesName=\'PRs\'\\n    field=\'nocode\'\\n    n={7}\\n/>\\n\\n## Top 20 companies contributing the most to LCDT repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/company-ranking-by-contributions\'\\n    formatSql={false}\\n    categoryIndex=\'company\'\\n    valueIndex=\'contributions\'\\n    seriesName=\'Contributions\'\\n    categoryType={false}\\n    field=\'nocode\'\\n    n={20}\\n/>\\n\\n## Top 20 countries/regions contributing the most to LCDT repos in 2021\\n\\n<CommonChart\\n    chart=\'worldmapchart\'\\n    category=\'archive/2021/country-ranking-by-contributions\'\\n    formatSql={false}\\n    categoryIndex=\'country_code\'\\n    valueIndex=\'contributions\'\\n    seriesName=\'Contributions\'\\n    field=\'nocode\'\\n    n={20}\\n/>\\n\\n## The rankings of LCDT repos measured by Z-score in 2021\\n\\nThe analytical results displayed above are generated based on just one single metric of these three: stars, PRs, or contributors. Now, we will use the [Z-score](https://en.wikipedia.org/wiki/Standard_score) method to rank the LCDT repos on GitHub. \\n\\nThis is the comprehensive ranking calculated by z-score:\\n\\n<CommonChart\\n    chart=\'zscorechart\'\\n    category=\'archive/2021/repo-ranking-by-z-score\'\\n    formatSql={false}\\n    field=\'nocode\'\\n    n={50}\\n/>"},{"id":"/deep-insight-into-open-source-databases","metadata":{"permalink":"/blog/deep-insight-into-open-source-databases","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/deep-insight-into-open-source-databases/index.mdx","source":"@site/blog/deep-insight-into-open-source-databases/index.mdx","title":"Deep Insight Into Open Source Databases","description":"On this page, we will share with you many deep insights into open source databases, such as the database popularity, database contributors, coding vitality, community feedback and so on.","date":"2022-05-03T00:00:00.000Z","formattedDate":"May 3, 2022","tags":[{"label":"insight","permalink":"/blog/tags/insight"}],"readingTime":5.015,"hasTruncateMarker":true,"authors":[{"name":"Jagger","title":"Engineer of TiDB Community","url":"https://github.com/634750802","imageURL":"https://github.com/634750802.png","key":"Jagger"}],"frontMatter":{"title":"Deep Insight Into Open Source Databases","date":"2022-05-03T00:00:00.000Z","authors":["Jagger"],"tags":["insight"],"image":"./oss-database.png","description":"On this page, we will share with you many deep insights into open source databases, such as the database popularity, database contributors, coding vitality, community feedback and so on.","keywords":["Open Source Database","tidb","top ranking","github","database","github archive","gitHub metrics"]},"prevItem":{"title":"Deep Insights into Low-code Development Tools","permalink":"/blog/deep-insight-into-lowcode-development-tools-2021"},"nextItem":{"title":"Deep Insights into Programming Languages","permalink":"/blog/deep-insight-into-programming-languages-2021"}},"content":"import {CommonChart} from \\"../../src/components/CommonChart\\";\\nimport ContributorsCharts from \\"../../src/components/ContributorsCharts\\";\\nconst osdbGroup = [507775, 60246359, 17165658, 41986369, 16563587, 6838921, 108110, 166515022, 48833910, 156018, 50229487, 20089857, 5349565, 6934395, 6358188, 11008207, 19961085, 206444, 30753733, 105944401, 31006158, 99919302, 50874442, 84240850, 28738447, 44781140, 372536760, 13124802, 146459443, 28449431, 23418517, 206417, 9342529, 19257422, 196353673, 172104891, 402945349, 11225014, 2649214, 41349039, 114187903, 20587599, 19816070, 69400326, 927442, 24494032]\\n\\nOn this page, we will share with you many deep insights into open source databases, such as the database popularity, database contributors, coding vitality, community feedback and so on. \\n\\nWe\u2019ll also share the SQL commands that generate all these analytical results above each chart, so you can use them on your own on TiDB Cloud following this [10-minute tutorial](/blog/try-it-yourself/). \\n\\n\x3c!--truncate--\x3e\\n\\n## Database Popularity\\n\\n### The popularity trend in the past ten years\\n\\nThe chart below displays the accumulated number of stars open source databases gained respectively each year and their star growth trend during the past ten years.\\n\\n<CommonChart\\n    chart=\'dynamic-stars\'\\n    category=\'archive/2021/repo-racing-by-stars\'\\n    formatSql={false}\\n    field=\'database\'\\n/>\\n\\n### Which databases experienced a popularity boom in 2021?\\n\\nThe chart below displays top 10 open source databases with the highest year-over-year growth rate of stars in 2021 alone.\\n\\n<CommonChart\\n  chart=\'yoychart\'\\n  category=\'archive/2021/repo-ranking-by-yoy-stars-growth\'\\n  formatSql={false}\\n  field=\'database\'\\n/>\\n\\n### Which databases barely gained influence in 2021?\\n\\nThe chart below displays top 10 open source databases with the lowest year-over-year growth rate of stars in 2021 alone. \\n\\n<CommonChart\\n    chart=\'yoychart\'\\n    category=\'archive/2021/repo-ranking-by-yoy-stars-growth-least\'\\n    formatSql={false}\\n    field=\'database\'\\n/>\\n\\n### Which databases were the new favorites in 2021?\\n\\nThe chart below displays the top open source databases that gained the most stars in 2021. \\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/2021/repo-ranking-by-stars-growth\'\\n  formatSql={false}\\n  categoryIndex=\'repo_name\'\\n  valueIndex=\'stars\'\\n  seriesName=\'Stars\'\\n  field=\'database\'\\n  n={10}\\n/>\\n\\n### Which countries & regions favor databases the most? \\n\\nThe map below describes the geographical distribution of database stargazers. The larger and darker the color spots on this map, the more database stargazers are distributed.\\n\\n<CommonChart\\n  chart=\'worldmapchart\'\\n  category=\'analyze-stars-map\'\\n  formatSql={false}\\n  categoryIndex=\'country_or_area\'\\n  valueIndex=\'count\'\\n  seriesName=\'stargazers\'\\n  effect={false}\\n  size={56}\\n  repoId={osdbGroup}\\n/>\\n\\n### Which companies like databases the most?\\n\\nThe pie chart below describes which company those database stargazers work for and how many stargazers those companies employ.\\n\\n<CommonChart\\n  chart=\'piechart\'\\n  category=\'analyze-stars-company\'\\n  formatSql={false}\\n  categoryIndex=\'company_name\'\\n  valueIndex=\'stargazers\'\\n  categoryType=\'owner\'\\n  seriesName=\'Stargazers\'\\n  repoId={osdbGroup}\\n/>\\n\\n## Database contributors \\n\\n### Which countries & regions led the database contributions in 2021? \\n\\nThe map below shows the geographic distribution of developers who pushed commits, resolved issues, or submitted pull requests to open source databases in 2021. The larger and darker the color spots on this map, the more database contributors were distributed.\\n\\n<CommonChart\\n  chart=\'worldmapchart\'\\n  category=\'archive/2021/country-ranking-by-contributions\'\\n  formatSql={false}\\n  categoryIndex=\'country_code\'\\n  seriesName=\'Contributions\'\\n  valueIndex=\'contributions\'\\n  field=\'database\'\\n/>\\n\\n### Which companies led the database contributions in 2021?\\n\\nThe chart below shows the employment distribution of developers who pushed commits, resolved issues, or submitted pull requests to open source databases in 2021.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/2021/company-ranking-by-contributions\'\\n  formatSql={false}\\n  categoryIndex=\'company\'\\n  valueIndex=\'contributions\'\\n  seriesName=\'Contributions\'\\n  categoryType={false}\\n  field=\'database\'\\n/>\\n\\n### Who were the leading individual contributors in 2021?\\n\\nThe chart below lists 20 most active individual contributors to open source databases in 2021 based on how many pull requests they opened.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/2021/repo-pr-creator-ranking-by-prs\'\\n  formatSql={false}\\n  categoryIndex=\'actor_login\'\\n  valueIndex=\'prs\'\\n  categoryType=\'owner\'\\n  seriesName=\'PRs\'\\n  field=\'database\'\\n  n={20}\\n/>\\n\\n### When did developers contribute?\\n\\nThe heat map below describes the number of push events that occur at a particular point of time (UTC). For each day and hour, the colored boxes indicate the number of push events. The lighter the color, the fewer push events; the darker the color, the more push events. You can learn from this heat map what time is the busiest for contributors, and roughly conclude which country or region distributes the most contributors.\\n\\n\\n<CommonChart\\n  chart=\'heatmapchart\'\\n  category=\'analyze-commits-time-distribution\'\\n  xIndex=\'hour\'\\n  yIndex=\'dayofweek\'\\n  valueIndex=\'pushes\'\\n  formatSql={false}\\n  repoId={osdbGroup}\\n/>\\n\\n## Database coding vitality\\n\\n### Which databases vibrantly maintained and updated itself in 2021?\\n\\nThe chart below displays top 10 open source databases that received the most pull requests in 2021 alone.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/2021/repo-ranking-by-prs\'\\n  formatSql={false}\\n  categoryIndex=\'repo_name\'\\n  valueIndex=\'prs\'\\n  seriesName=\'PRs\'\\n  field=\'database\'\\n  n={10}\\n/>\\n\\n## Database user feedback \\n\\n### Which databases have the widest feedback sources?\\n\\nThe chart below displays the number of issue creators of leading open source databases each year and their growth trend during the past ten years.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/2021/repo-ranking-by-issue-creators\'\\n  formatSql={false}\\n  categoryIndex=\'repo_name\'\\n  valueIndex=\'issue_creators\'\\n  seriesName=\'Issue Creators\'\\n  categoryType={false}\\n  field=\'database\'\\n  n={10}\\n/>\\n\\n### Which databases gave the fastest first response in 2021?\\n\\nThe bar chart below shows the median time each open source database needs to make its first response to an issue.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/2021/repo-ranking-by-issue-open-to-first-respond\'\\n  formatSql={false}\\n  categoryIndex=\'repo_name\'\\n  valueIndex=\'days\'\\n  seriesName=\'Days\'\\n  categoryType={false}\\n  field=\'database\'\\n  n={10}\\n/>\\n\\n#### Which databases were the most efficient in feedback resolution in 2021?\\n\\nThe bar chart below shows the median time each open source database needs to close an issue.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/2021/repo-ranking-by-issue-open-to-close\'\\n  formatSql={false}\\n  categoryIndex=\'repo_name\'\\n  valueIndex=\'days\'\\n  seriesName=\'Days\'\\n  categoryType={false}\\n  field=\'database\'\\n  n={10}\\n/>\\n\\n### Who gave the feedback in 2021?\\n\\nThe map below shows the geographical distribution of developers who submitted issues to open source databases. The larger and darker the color spots on this map, the more issue openers were distributed. \\n\\n<CommonChart\\n  chart=\'worldmapchart\'\\n  category=\'analyze-issue-creators-map\'\\n  formatSql={false}\\n  categoryIndex=\'country_or_area\'\\n  valueIndex=\'count\'\\n  seriesName=\'Issue openers\'\\n  effect={false}\\n  size={56}\\n  repoId={osdbGroup}\\n/>\\n\\n## Community Robustness\\n\\n### Which databases have the most heavy contributors? \\n\\nThe chart below displays the number of heavy contributors (who submitted more than 100 pull requests), medium contributors (who submitted more than 10 but less than 100 pull requests), and light contributors (who submitted less than 10 pull requests) of leading open source databases. The chart also ranks these databases based on their number of heavy contributors. \\n\\n<ContributorsCharts type=\'contributors\' field=\'database\'/>\\n\\n### Which databases are heavily contributed?\\n\\nThe chart below displays the number of pull requests submitted by heavy contributors, medium contributors, and light contributors. The chart also ranks these databases based on the number of pull requests submitted by heavy contributors. \\n\\n<ContributorsCharts type=\'prs\' field=\'database\'/>\\n\\n### How fast did databases approve their code changes?\\n\\nThe chart below shows the median time each open source database needs from submitting to merging a pull request.\\n\\n<CommonChart\\n  chart=\'barchart\'\\n  category=\'archive/2021/repo-ranking-by-pr-open-to-merge\'\\n  formatSql={false}\\n  categoryIndex=\'repo_name\'\\n  valueIndex=\'days\'\\n  seriesName=\'Days\'\\n  categoryType={false}\\n  field=\'database\'\\n  n={20}\\n/>\\n\\n## Database programming languages\\n\\n### Which languages were most favored in 2021?\\n\\nThe chart below shows the top programming languages used in pull requests submitted to open source databases in 2021.\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/language-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'language\'\\n    valueIndex=\'prs\'\\n    categoryType=\'lang\'\\n    seriesName=\'PRs\'\\n    field=\'database\'\\n/>"},{"id":"/deep-insight-into-programming-languages-2021","metadata":{"permalink":"/blog/deep-insight-into-programming-languages-2021","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/deep-insight-into-programming-languages-2021/index.mdx","source":"@site/blog/deep-insight-into-programming-languages-2021/index.mdx","title":"Deep Insights into Programming Languages","description":"In this chapter, we will share with you some of the top programming language repos (PL repos) on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on.","date":"2022-05-03T00:00:00.000Z","formattedDate":"May 3, 2022","tags":[{"label":"insight","permalink":"/blog/tags/insight"}],"readingTime":1.59,"hasTruncateMarker":true,"authors":[{"name":"Jagger","title":"Engineer of TiDB Community","url":"https://github.com/634750802","imageURL":"https://github.com/634750802.png","key":"Jagger"}],"frontMatter":{"title":"Deep Insights into Programming Languages","date":"2022-05-03T00:00:00.000Z","authors":["Jagger"],"tags":["insight"],"image":"./language.png","description":"In this chapter, we will share with you some of the top programming language repos (PL repos) on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on.","keywords":["Programming Language","tidb","top ranking","github","database","github archive","gitHub metrics"]},"prevItem":{"title":"Deep Insight Into Open Source Databases","permalink":"/blog/deep-insight-into-open-source-databases"},"nextItem":{"title":"Deep Insights into Web Frameworks","permalink":"/blog/deep-insight-into-web-framework-2021"}},"content":"import {CommonChart} from \\"../../src/components/CommonChart\\";\\n\\nIn this chapter, we will share with you some of **the top programming language repos (PL repos) on GitHub in 2021** measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on. \\n\\n\x3c!--truncate--\x3e\\n\\nNote: \\n\\n1. You can move your cursor onto any of the repository bars/lines on the chart and get the exact number. \\n2. The SQL commands above each chart are what we use on TiDB Cloud to get the analytical results. Try those SQL commands by yourselves on TiDB Cloud with this [10-minute tutorial](/blog/try-it-yourself/).\\n\\n\\n## Star history of top PL repos since 2011\\n\\n<CommonChart\\n    chart=\'dynamic-stars\'\\n    category=\'archive/2021/repo-racing-by-stars\'\\n    formatSql={false}\\n    field=\'programming_language\'\\n/>\\n\\n## Top 10 most starred PL repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-stars-growth\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'stars\'\\n    seriesName=\'Stars\'\\n    field=\'programming_language\'\\n    n={10}\\n/>\\n\\n## Top 10 PL repos with the most PRs in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'prs\'\\n    seriesName=\'PRs\'\\n    field=\'programming_language\'\\n    n={10}\\n/>\\n\\n## Top 20 developers contributed the most PRs to PL repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-pr-creator-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'actor_login\'\\n    valueIndex=\'prs\'\\n    categoryType=\'owner\'\\n    seriesName=\'PRs\'\\n    field=\'programming_language\'\\n    n={20}\\n/>\\n\\n\\n## Top 9 PL repos with the highest YoY growth rate of stars in 2021\\n\\n<CommonChart\\n    chart=\'yoychart\'\\n    category=\'archive/2021/repo-ranking-by-yoy-stars-growth\'\\n    formatSql={false}\\n    field=\'programming_language\'\\n/>\\n\\n## Top 10 PL repos with the lowest YoY growth rate of stars in 2021\\n\\n<CommonChart\\n    chart=\'yoychart\'\\n    category=\'archive/2021/repo-ranking-by-yoy-stars-growth-least\'\\n    formatSql={false}\\n    field=\'programming_language\'\\n/>\\n\\n## Top 20 companies contributing the most to PL repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/company-ranking-by-contributions\'\\n    formatSql={false}\\n    categoryIndex=\'company\'\\n    valueIndex=\'contributions\'\\n    seriesName=\'Contributions\'\\n    categoryType={false}\\n    field=\'programming_language\'\\n    n={20}\\n/>\\n\\n## Top countries or regions contributing to OSS programming languages\\n\\n<CommonChart\\n    chart=\'worldmapchart\'\\n    category=\'archive/2021/country-ranking-by-contributions\'\\n    formatSql={false}\\n    categoryIndex=\'country_code\'\\n    valueIndex=\'contributions\'\\n    seriesName=\'Contributions\'\\n    field=\'programming_language\'\\n    n={255}\\n/>\\n\\n## The rankings of PL repos measured by Z-score in 2021\\n\\nThe analytical results displayed above are generated based on just one single metric of these three: stars, PRs, or contributors. Now, we will use the [Z-score](https://en.wikipedia.org/wiki/Standard_score) method to rank PL repos on GitHub.\\n\\nThis is the comprehensive ranking calculated by z-score:\\n\\n<CommonChart\\n    chart=\'zscorechart\'\\n    category=\'archive/2021/repo-ranking-by-z-score\'\\n    formatSql={false}\\n    field=\'programming_language\'\\n    n={50}\\n/>"},{"id":"/deep-insight-into-web-framework-2021","metadata":{"permalink":"/blog/deep-insight-into-web-framework-2021","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/deep-insight-into-web-framework-2021/index.mdx","source":"@site/blog/deep-insight-into-web-framework-2021/index.mdx","title":"Deep Insights into Web Frameworks","description":"In this chapter, we will share with you some of the top Web Framework repos (WF repos) on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on.","date":"2022-05-03T00:00:00.000Z","formattedDate":"May 3, 2022","tags":[{"label":"insight","permalink":"/blog/tags/insight"}],"readingTime":2.055,"hasTruncateMarker":true,"authors":[{"name":"Jagger","title":"Engineer of TiDB Community","url":"https://github.com/634750802","imageURL":"https://github.com/634750802.png","key":"Jagger"}],"frontMatter":{"title":"Deep Insights into Web Frameworks","date":"2022-05-03T00:00:00.000Z","authors":["Jagger"],"tags":["insight"],"image":"./webframework.png","description":"In this chapter, we will share with you some of the top Web Framework repos (WF repos) on GitHub in 2021 measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on.","keywords":["Web Framework","tidb","top ranking","github","database","github archive","gitHub metrics"]},"prevItem":{"title":"Deep Insights into Programming Languages","permalink":"/blog/deep-insight-into-programming-languages-2021"},"nextItem":{"title":"Explore Deep in 4.6 Billion GitHub Events","permalink":"/blog/explore-deep-in-4.6-billion-github-events"}},"content":"import {CommonChart} from \\"../../src/components/CommonChart\\";\\n\\nIn this chapter, we will share with you some of the **top Web Framework repos (WF repos) on GitHub in 2021** measured by different metrics including the number of stars, PRs, contributors, countries, regions and so on. \\n\\n\x3c!--truncate--\x3e\\n\\nNote: \\n1. You can move your cursor onto any of the repository bars/lines on the chart and get the exact number. \\n2. The SQL commands above each chart are what we use on our TiDB Cloud to get the analytical results. Try those SQL commands by yourselves on TiDB Cloud with [this 10-minute tutorial](/blog/try-it-yourself/).\\n\\n## Star history of top Web Framework repos since 2011\\n\\nThe number of stars is often thought of as a measure of whether a GitHub repository is popular or not. We sort all web framework repositories from GitHub by the total number of historical stars since 2011. For visualizing the results more intuitively, we show the top 10 open source databases by using an interactive line chart.\\n\\n<CommonChart\\n    chart=\'dynamic-stars\'\\n    category=\'archive/2021/repo-racing-by-stars\'\\n    formatSql={false}\\n    field=\'web_framework\'\\n/>\\n\\n## Top 10 most starred Web Framework repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-stars-growth\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'stars\'\\n    seriesName=\'Stars\'\\n    field=\'web_framework\'\\n    n={10}\\n/>\\n\\n\\n## Top 10 Web Framework repos with the most PRs in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'repo_name\'\\n    valueIndex=\'prs\'\\n    seriesName=\'PRs\'\\n    field=\'web_framework\'\\n    n={10}\\n/>\\n\\n## Top 20 developers contributed the most PRs to Web Framework repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/repo-pr-creator-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'actor_login\'\\n    valueIndex=\'prs\'\\n    categoryType=\'owner\'\\n    seriesName=\'PRs\'\\n    field=\'web_framework\'\\n    n={20}\\n/>\\n\\n\\n## Top 20 Web Framework repos with the highest YoY growth rate of stars in 2021\\n\\n<CommonChart\\n    chart=\'yoychart\'\\n    category=\'archive/2021/repo-ranking-by-yoy-stars-growth\'\\n    formatSql={false}\\n    field=\'web_framework\'\\n/>\\n\\n\\n## Top 10 Web Framework repos with the lowest YoY growth rate of stars in 2021\\n\\n<CommonChart\\n    chart=\'yoychart\'\\n    category=\'archive/2021/repo-ranking-by-yoy-stars-growth-least\'\\n    formatSql={false}\\n    field=\'web_framework\'\\n/>\\n\\n## Top 10 most used programming languages in Web Framework repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/language-ranking-by-prs\'\\n    formatSql={false}\\n    categoryIndex=\'language\'\\n    valueIndex=\'prs\'\\n    categoryType=\'lang\'\\n    seriesName=\'PRs\'\\n    field=\'web_framework\'\\n/>\\n\\n## Top 20 companies contributing the most to Web Framework repos in 2021\\n\\n<CommonChart\\n    chart=\'barchart\'\\n    category=\'archive/2021/company-ranking-by-contributions\'\\n    formatSql={false}\\n    categoryIndex=\'company\'\\n    valueIndex=\'contributions\'\\n    seriesName=\'Contributions\'\\n    categoryType={false}\\n    field=\'web_framework\'\\n    n={20}\\n/>\\n\\n\\n## Top 10 countries/regions contributing the most to Web Framework repos in 2021\\n\\n<CommonChart\\n    chart=\'worldmapchart\'\\n    category=\'archive/2021/country-ranking-by-contributions\'\\n    formatSql={false}\\n    categoryIndex=\'country_code\'\\n    valueIndex=\'contributions\'\\n    seriesName=\'Contributions\'\\n    field=\'web_framework\'\\n    n={10}\\n/>\\n\\n## The Rankings of Web Framework repos measured by Z-score in 2021\\n\\nThe analytical results displayed above are generated based on just one single metric of these three: stars, PRs, or contributors. Now, we will use the [Z-score](https://en.wikipedia.org/wiki/Standard_score) method to rank the WF repos on GitHub.  \\n\\nThis is the comprehensive ranking calculated by z-score:\\n\\n<CommonChart\\n    chart=\'zscorechart\'\\n    category=\'archive/2021/repo-ranking-by-z-score\'\\n    formatSql={false}\\n    field=\'web_framework\'\\n    n={50}\\n/>"},{"id":"/explore-deep-in-4.6-billion-github-events","metadata":{"permalink":"/blog/explore-deep-in-4.6-billion-github-events","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/explore-deep-in-4.6-billion-github-events/index.md","source":"@site/blog/explore-deep-in-4.6-billion-github-events/index.md","title":"Explore Deep in 4.6 Billion GitHub Events","description":"Here you can find the answer of what does a view of 4.6 billion Github events really look like and what secrets and values can be discovered in such an enormous amount of data.","date":"2022-05-03T00:00:00.000Z","formattedDate":"May 3, 2022","tags":[{"label":"tidbcloud","permalink":"/blog/tags/tidbcloud"}],"readingTime":9.355,"hasTruncateMarker":true,"authors":[{"name":"Fendy Feng","title":"Technical Content Developer","url":"https://github.com/septemberfd","imageURL":"https://github.com/septemberfd.png","key":"fendy"}],"frontMatter":{"title":"Explore Deep in 4.6 Billion GitHub Events","date":"2022-05-03T00:00:00.000Z","authors":["fendy"],"tags":["tidbcloud"],"image":"./banner-ossinsight-explore-deep.jpg","description":"Here you can find the answer of what does a view of 4.6 billion Github events really look like and what secrets and values can be discovered in such an enormous amount of data.","keywords":["Popularity repositories","distribution of stargazer","tidb","top rankings","github","database","github archive","gitHub metrics","compare oss"]},"prevItem":{"title":"Deep Insights into Web Frameworks","permalink":"/blog/deep-insight-into-web-framework-2021"},"nextItem":{"title":"SaaS Insight for Building a Real-time CRM Application","permalink":"/blog/saas-insight-for-building-a-real-time-crm-application"}},"content":"4.6 billion is literally an astronomical figure. The richest star map of our galaxy, brought by Gaia space observatory, includes just under 2 billion stars. What does a view of 4.6 billion GitHub events really look like? What secrets and values can be discovered in such an enormous amount of data? \\n\\nHere you go: [OSSInsight.io](https://ossinsight.io/)** can help you find the answer**. It\u2019s a useful insight tool that can give you the most updated open source intelligence, and help you deeply understand any single GitHub project or quickly compare any two projects by digging deep into 4.6 billion GitHub events in real time. Here are some ways you can play with it.\\n\\n## Compare any two GitHub projects\\n\\nDo you wonder how different projects have performed and developed over time? Which project is worthy of more attention? **[OSSInsight.io](https://ossinsight.io/)** can answer your questions via the [Compare Projects](https://ossinsight.io/analyze/pingcap/tidb) page.\\n\\nLet\u2019s take the [Kubernetes repository](https://github.com/kubernetes/kubernetes)  (K8s) and Docker\u2019s [Moby repository](https://github.com/moby/moby) as examples and compare them in terms of popularity and coding vitality. \\n\\n\\n### **Popularity**\\n\\nTo compare the popularity of two repositories, we use multiple metrics including the number of stars, the growth trend of stars over time, and stargazers\u2019 geographic and employment distribution. \\n\\n#### **Number of stars**\\n\\nThe line chart below shows the accumulated number of stars of K8s and Moby each year. According to the chart, Moby was ahead of K8s until late 2019. The star growth of Moby slowed after 2017 while K8s has kept a steady growth pace. \\n\\n![](./the-star-history.png)\\n\\n<center><em>The star history of K8s and Moby</em></center>\\n\\n\\n#### **Geographical distribution of stargazers**\\n\\nThe map below shows the stargazers\u2019 geographical distribution of Moby and K8s. As you can see, their stargazers are scattered around the world with the majority coming from the US, Europe, and China.\\n\\n![](./geographicla-distribution-of-stargazers.png)\\n\\n\\n<center><em>The geographical distribution of K8s and Moby stargazers</em></center>\\n\\n#### **Employment distribution of stargazers**\\n\\nThe chart below shows the stargazers\u2019 employment of K8s (red) and Moby (dark blue). Both of their stargazers work in a wide range of industries, and most come from leading dotcom companies such as Google, Tencent, and Microsoft. The difference is that the top two companies of K8s\u2019 stargazers are  Google and Microsoft from the US, while Moby\u2019s top two followers are Tencent and Alibaba from China.  \\n\\n![](./employment-distribution-of-stargazers.png)\\n\\n\\n<center><em>The employment distribution of K8s and Moby stargazers</em></center>\\n\\n\x3c!--truncate--\x3e\\n\\n### **Coding vitality**\\n\\nTo compare the coding vitality of two GitHub projects, we use many metrics including the growth trend of pull requests (PRs), the monthly number of PRs, commits and pushes, and the heat map of developers\u2019 contribution time.  \\n\\n#### **Number of commits and pushes**\\n\\nThe bar chart below shows the number of commits and pushes submitted to K8s (top) and Moby (bottom) each month after their inception. Generally speaking, K8s has more pushes and commits than Moby, and their number grew stably until 2020 followed by a slowdown afterwards. Moby\u2019s monthly pushes and commits had a minor growth between 2015 and 2017, and then barely increased after 2018.\\n\\n![](./monthly-pushes-and-commits.png)\\n\\n<center><em>The monthly pushes and commits of K8s (top) and Moby (bottom)</em></center>\\n\\n#### **Number of PRs**\\n\\nThe charts below show the monthly and accumulated number of PRs of the two repositories. As you can see, K8s has received stable and consistent PR contributions ever since its inception and its accumulated number of PRs has also grown steadily. Moby had vibrant PR submissions before late 2017, but started to drop afterwards. Its accumulated number of PRs reached a plateau in 2017, which has remained the case ever since. \\n\\n![](./monthly-and-accumulated-pr-number.png)\\n\\n\\n<center><em>The monthly and accumulated PR number of K8s (top) and Moby (bottom)</em></center>\\n\\n#### **Developers\u2019 contribution time**\\n\\nThe following heat map shows developers\u2019 contribution time for K8s (left) and Moby (right). Each square represents one hour in a day. The darker the color, the more contributions occur during that time. K8s has many more dark parts than Moby, and K8s\u2019 contributions occur almost 24 hours a day, 7 days a week. K8s definitely has more dynamic coding activities than Moby. \\n\\n![](./heat-map.png)\\n\\n\\n<center><em>Heat map of developers\u2019 contribution time of K8s (left) and Moby (right)</em></center>\\n\\n<br />\\n\\n**Taken together**, these metrics show that while both K8s and Moby are popular across industries world-wide, K8s has more vibrant coding activities than Moby. K8s is continuously gaining popularity and coding vitality while Moby is falling in both over time.\\n\\nPopularity and coding vitality are just two dimensions to compare repositories. If you want to discover more insights or compare other projects you are interested in, feel free to visit the [Compare](https://ossinsight.io/analyze/pingcap/tidb) page and explore it for yourself.  \\n\\nOf course, you can use this same page to **deeply explore any single GitHub project** and gain the most up-to-date insights about them. The key metrics and the corresponding changes are presented in a panoramic view. More in-depth analytics such as code changes by PR size groups and PR lines are also available. Explore it for yourself and you\u2019d be surprised. Have fun. \\n\\n![](./panoramic-view-of-key-github-metrics.png)\\n\\n<center><em>Panoramic view of key GitHub metrics (K8s as an example)</em></center>\\n\\n<br />\\n\\n![](./total-pr-number-each-month-and-pr-groups.png)\\n\\n<center><em>  Total PR number each month/PR groups (K8s as an example)</em></center>\\n\\n<br />\\n\\n![](./number-of-lines-of-code-change-each-month.png)\\n\\n<center><em>The number of lines of code change each month (K8s as an example)</em></center>\\n\\n\\n## Key open source insights\\n\\n[OSSInsight.io](https://ossinsight.io/) does more than explore or compare repositories. **It gives you [historical, real-time, and custom open source insights](https://ossinsight.io/database/deep-insight-into-open-source-databases).** In this section, we\u2019ll share some key insights in open source databases and programming languages. If you want to gain insights in other areas, you can explore the [Insights](https://ossinsight.io/database/deep-insight-into-open-source-databases/)  page for yourself. \\n\\n**Note**: If you want to get those analytical results by yourself, you can execute the SQL commands above each chart on TiDB Cloud with ease following this [10-minute tutorial](https://ossinsight.io/blog/try-it-yourself/). \\n\\n\\n### **Rust: the most active programming language**\\n\\nRust was first released in 2012 and has been among the leading programming languages for 10 years. It has the most active repository with a total of 103,047 PRs at the time of writing. \\n\\n<details><summary>Click here to show SQL commands</summary>\\n<p>\\n\\n```sql\\nSELECT\\n    programming_language_repos.name AS repo_name,\\n    COUNT(*)      AS num\\nFROM github_events\\n         JOIN programming_language_repos ON programming_language_repos.id = github_events.repo_id\\nWHERE type = \'PullRequestEvent\'\\n  AND action = \'opened\'\\nGROUP BY 1\\nORDER BY 2 DESC\\nLIMIT 10\\n```\\n\\n</p>\\n</details>\\n\\n![](./pr-number-of-pl-repos.png)\\n\\n\\n<center><em>PR numbers of the leading programming languages</em></center>\\n\\n### **Go: the new favorite and the fastest growing programming language**\\n\\nAccording to **[OSSInsight.io](https://ossinsight.io/)**, 10 programming languages dominate the open source community. Go is the most popular with 108,317 stars, followed by Node and TypeScript. Go is also the fastest growing language in popularity.\\n\\n<details><summary>Click here to show SQL commands</summary>\\n<p>\\n\\n```sql\\nWITH repo_stars AS (\\n    SELECT\\n        repo_id,\\n        ANY_VALUE(repos.name) AS repo_name,\\n        COUNT(distinct actor_login) AS stars\\n    FROM github_events\\n         JOIN programming_language_repos repos ON repos.id = github_events.repo_id\\n    WHERE type = \'WatchEvent\'\\n    GROUP BY 1\\n), top_10_repos AS (\\n    SELECT\\n        repo_id, repo_name, stars\\n    FROM repo_stars rs\\n    ORDER BY stars DESC\\n    LIMIT 10\\n), tmp AS (\\n    SELECT\\n        event_year,\\n        tr.repo_name AS repo_name,\\n        COUNT(*) AS year_stars\\n    FROM github_events\\n         JOIN top_10_repos tr ON tr.repo_id = github_events.repo_id\\n    WHERE type = \'WatchEvent\' AND event_year <= 2021\\n    GROUP BY 2, 1\\n    ORDER BY 1 ASC, 2\\n), tmp1 AS (\\n    SELECT\\n        event_year,\\n        repo_name,\\n        SUM(year_stars) OVER(partition by repo_name order by event_year ASC) as stars\\n    FROM tmp\\n    ORDER BY event_year ASC, repo_name\\n)\\nSELECT event_year, repo_name, stars FROM tmp1\\n```\\n\\n</p>\\n</details>\\n\\n![](./star-growth-trends-of-leading-programming-languages.png)\\n\\n<center><em>The star growth trends of leading programming languages</em></center>\\n\\n\\n### **Microsoft and Google: the top two programing languages contributors**\\n\\nAs world-renowned high-tech companies, Microsoft and Google take the lead in open source language contributions with a total of 1,443 and 947 contributors respectively at the time of writing. \\n\\n<details><summary>Click here to show SQL commands</summary>\\n<p>\\n\\n```sql\\nSELECT\\n    TRIM(LOWER(REPLACE(u.company, \'@\', \'\'))) AS company,\\n    COUNT(DISTINCT actor_id)                 AS num\\nFROM\\n    github_events github_events\\n    JOIN programming_language_repos db ON db.id = github_events.repo_id\\n    JOIN users u ON u.login = github_events.actor_login\\nWHERE\\n    github_events.type IN (\\n        \'IssuesEvent\', \'PullRequestEvent\',\'IssueCommentEvent\',\\n        \'PullRequestReviewCommentEvent\', \'CommitCommentEvent\',\\n        \'PullRequestReviewEvent\'\\n    )\\n    AND u.company IS NOT NULL\\n    AND u.company != \'\'\\n    AND u.company != \'none\'\\nGROUP BY 1\\nORDER BY 2 DESC\\nLIMIT 20;\\n```\\n\\n</p>\\n</details>\\n\\n![](./companies-who-contribute-the-most-to-programing-languages.png)\\n\\n\\n<center><em>Companies who contribute the most to programing languages</em></center>\\n\\n\\n### **Elasticsearch draws the most attention**\\n\\nElasticsearch was one of the first open source databases. It is the most liked database with 64,554 stars, followed by Redis and Prometheus. From 2011 to 2016, Elasticseasrch and Redis shared the top spot until Elasticsearch broke away in 2017.\\n\\n<details><summary>Click here to show SQL commands</summary>\\n<p>\\n\\n```sql\\nWITH repo_stars AS (\\n    SELECT\\n        repo_id,\\n        ANY_VALUE(repos.name) AS repo_name,\\n        COUNT(distinct actor_login) AS stars\\n    FROM github_events\\n         JOIN db_repos repos ON repos.id = github_events.repo_id\\n    WHERE type = \'WatchEvent\'\\n    GROUP BY 1\\n), top_10_repos AS (\\n    SELECT\\n        repo_id, repo_name, stars\\n    FROM repo_stars rs\\n    ORDER BY stars DESC\\n    LIMIT 10\\n), tmp AS (\\n    SELECT\\n        event_year,\\n        tr.repo_name AS repo_name,\\n        COUNT(*) AS year_stars\\n    FROM github_events\\n         JOIN top_10_repos tr ON tr.repo_id = github_events.repo_id\\n    WHERE type = \'WatchEvent\' AND event_year <= 2021\\n    GROUP BY 2, 1\\n    ORDER BY 1 ASC, 2\\n), tmp1 AS (\\n    SELECT\\n        event_year,\\n        repo_name,\\n        SUM(year_stars) OVER(partition by repo_name order by event_year ASC) as stars\\n    FROM tmp\\n    ORDER BY event_year ASC, repo_name\\n)\\nSELECT event_year, repo_name, stars FROM tmp1\\n```\\n\\n</p>\\n</details>\\n\\n\\n![](./star-growth-trend-of-leading-databases.png)\\n\\n\\n<center><em>The star growth trend of leading databases</em></center>\\n\\n\\n### **China: the number one fan of open source databases**\\n\\nChina has the most open source database followers with 11,171 stargazers of database repositories, followed by the US and Europe. \\n\\n<details><summary>Click here to show SQL commands</summary>\\n<p>\\n\\n```sql\\nselect upper(u.country_code) as country_or_area, count(*) as count, count(*) / max(s.total) as percentage\\nfrom github_events\\nuse index(index_github_events_on_repo_id)\\nleft join users u ON github_events.actor_login = u.login\\njoin (\\n    -- Get the number of people has the country code.\\n    select count(*) as total\\n    from github_events\\n    use index(index_github_events_on_repo_id)\\n    left join users u ON github_events.actor_login = u.login\\n    where repo_id in (507775, 60246359, 17165658, 41986369, 16563587, 6838921, 108110, 166515022, 48833910, 156018, 50229487, 20089857, 5349565, 6934395, 6358188, 11008207, 19961085, 206444, 30753733, 105944401, 31006158, 99919302, 50874442, 84240850, 28738447, 44781140, 372536760, 13124802, 146459443, 28449431, 23418517, 206417, 9342529, 19257422, 196353673, 172104891, 402945349, 11225014, 2649214, 41349039, 114187903, 20587599, 19816070, 69400326, 927442, 24494032) and github_events.type = \'WatchEvent\' and u.country_code is not null\\n) s\\nwhere repo_id in (507775, 60246359, 17165658, 41986369, 16563587, 6838921, 108110, 166515022, 48833910, 156018, 50229487, 20089857, 5349565, 6934395, 6358188, 11008207, 19961085, 206444, 30753733, 105944401, 31006158, 99919302, 50874442, 84240850, 28738447, 44781140, 372536760, 13124802, 146459443, 28449431, 23418517, 206417, 9342529, 19257422, 196353673, 172104891, 402945349, 11225014, 2649214, 41349039, 114187903, 20587599, 19816070, 69400326, 927442, 24494032) and github_events.type = \'WatchEvent\' and u.country_code is not null\\ngroup by 1\\norder by 2 desc;\\n```\\n\\n</p>\\n</details>\\n\\n![](./geographical-distribution-database-stargazers.png)\\n\\n\\n<center><em>The geographical distribution of open source database stargazers</em></center>\\n\\n\\n**[OSSInsight.io](https://ossinsight.io/)** also allows you to create your own custom insights into any GitHub repository created after 2011. You\u2019re welcome to visit the [Insights page](https://ossinsight.io/database/deep-insight-into-open-source-databases) to explore more. \\n\\n\\n## Run your own analytics with TiDB Cloud\\n\\nAll the analytics on **[OSSInsight.io](https://ossinsight.io/)** are powered by [TiDB Cloud](https://www.pingcap.com/tidb-serverless/), a fully-managed database as a service. If you want to run your own analytics and get your own insights, [sign up for a TiDB Cloud account](https://tidbcloud.com/free-trial/?utm_source=ossinsight&utm_medium=community) and try it for yourself with this [10-minute tutorial](https://ossinsight.io/blog/try-it-yourself/).\\n\\n## Contact us \\n\\nDo you find **[OSSInsight.io](https://ossinsight.io/)** useful and fun to work with? Do you have any question or feedback to share with us? Feel free to [file an issue](https://github.com/pingcap/ossinsight/issues/new) on GitHub or follow us on [Twitter](https://twitter.com/OSSInsight/) to get the latest information. You\u2019re also welcome to share this insight tool with your friends."},{"id":"/saas-insight-for-building-a-real-time-crm-application","metadata":{"permalink":"/blog/saas-insight-for-building-a-real-time-crm-application","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/saas-insight-for-building-a-real-time-crm-application/index.md","source":"@site/blog/saas-insight-for-building-a-real-time-crm-application/index.md","title":"SaaS Insight for Building a Real-time CRM Application","description":"This article describes how to building a real-time CRM application in a better way. Includes the potential database solutions.","date":"2022-05-01T00:00:00.000Z","formattedDate":"May 1, 2022","tags":[{"label":"tidb","permalink":"/blog/tags/tidb"}],"readingTime":2.715,"hasTruncateMarker":false,"authors":[{"name":"ilovesoup","title":"PMM of PingCAP","url":"https://github.com/ilovesoup","imageURL":"https://github.com/ilovesoup.png","key":"ilovesoup"}],"frontMatter":{"title":"SaaS Insight for Building a Real-time CRM Application","description":"This article describes how to building a real-time CRM application in a better way. Includes the potential database solutions.","image":"./thumbnail.png","date":"2022-05-01T00:00:00.000Z","authors":["ilovesoup"],"tags":["tidb"]},"prevItem":{"title":"Explore Deep in 4.6 Billion GitHub Events","permalink":"/blog/explore-deep-in-4.6-billion-github-events"},"nextItem":{"title":"[Outdated] Use TiDB Cloud to Analyze GitHub Events in 10 Minutes","permalink":"/blog/try-it-yourself"}},"content":"> Providing insights on large volume of email data might not be as easy as we thought. While data coming in real-time, indices and metadata are to be built consistently. To make things worse, the data volume is beyond traditional single node databases\' reach.\\n\\n## Background\\n\\nTo store large volumes of real-time user data like email and provide insights is not easy. If your application is layered on top of Gmail to automatically extract and organize the useful information buried inside of our inboxes.\\n\\n It became clear that they were going to need a better system for organizing terabytes of email metadata to power collaboration as their customer base rapidly increased, it is not easy to provide insights. You need to organize email data by first applying a unique identifier to the emails and then proactively indexing the email metadata. The unique identifier is what connects the same email headers across. For each email inserted in real-time, the system extracts meta information from it and builds indices for high concurrent access. When data volume is small, it\'s all good: traditional databases provide all you need. However, when data size grows beyond a single node\'s capacity, everything becomes very hard.\\n\\n## Potential Database Solutions\\n\\nRegarding databases, there are some options you might consider:\\n\\n1. **NoSQL database.** While fairly scalable, it does not provide you indexing and comprehensive query abilities. You might end up implementing them in your application code.\\n2. **Sharing cluster of databases.** Designing sharding key and paying attention to the limitations between shards are painful. It might be fine for applications with simple schema designs, but it will be too complicated for CRM. Moreover, it\'s very hard to maintain.\\n3. **Analytical databases.** They are fine for dashboard and reporting. But not fine for high concurrent updates and index based serving.\\n\\n## How to get real-time insights\\n\\n[TiDB](https://docs.pingcap.com/tidb/stable/overview?utm_source=ossinsight&utm_medium=referral) is a distributed database with user experience of traditional databases. It looks like a super large MySQL without the limitations of NoSQL and sharding cluster solutions. With TiDB, you can simply have the base information, indices and metadata being updated in a concurrent manner with the help of cross-node transaction ability. \\n\\nTo build such a system, you just need following steps:\\n\\n1. **Create schemas** according to your access pattern with indices on user name, organization, job title etc.\\n2. **Use streaming system** to gather and extract meta information from your base data\\n3. **Insert into TiDB via ordinary MySQL client driver like JDBC.** You might want to gather data in small batches of hundreds of rows to speed up ingestion. In a single transaction, updates on base data, indices and meta information are guaranteed to be consistent.\\n4. Optionally, **deploy a couple of [TiFlash](https://docs.pingcap.com/tidb/stable/tiflash-overview?utm_source=ossinsight&utm_medium=referral) nodes** to speed up large scale reporting queries.\\n5. **Access the data** just like in MySQL and you are all done. SQL features for analytics like aggregations, multi-joins or window functions are all supported with great performance.\\n\\nFor more cases, please see [here](https://en.pingcap.com/customers/?utm_source=ossinsight&utm_medium=referral).\\n\\n\\n\\n:::info\\n### \ud83c\udf1f Details in how OSS Insight works\\n\\nGo to read [Use TiDB Cloud to Analyze GitHub Events in 10 Minutes](/blog/try-it-yourself) and use the [Serverless Tier](https://tidbcloud.com/free-trial/?utm_source=ossinsight&utm_medium=community) TiDB Cloud Cluster.\\n\\nYou can find how we deal with massive github data in [Data Preparation for Analytics](/blog/how-it-works) as well!\\n:::"},{"id":"/try-it-yourself","metadata":{"permalink":"/blog/try-it-yourself","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/try-it-yourself/index.md","source":"@site/blog/try-it-yourself/index.md","title":"[Outdated] Use TiDB Cloud to Analyze GitHub Events in 10 Minutes","description":"In this tutorial, we will provide you with a piece of sample data of all GitHub events occurring on January 1, 2022, and walk you through on how to use TiDB Cloud to analyze this data in 10 minutes.","date":"2022-04-01T00:00:00.000Z","formattedDate":"April 1, 2022","tags":[{"label":"tidbcloud","permalink":"/blog/tags/tidbcloud"}],"readingTime":4.905,"hasTruncateMarker":true,"authors":[{"name":"Fendy Feng","title":"Technical Content Developer","url":"https://github.com/septemberfd","imageURL":"https://github.com/septemberfd.png","key":"fendy"},{"name":"hooopo","title":"Engineer of TiDB Community","url":"https://twitter.com/hooopo","imageURL":"https://github.com/hooopo.png","key":"hooopo"}],"frontMatter":{"title":"[Outdated] Use TiDB Cloud to Analyze GitHub Events in 10 Minutes","date":"2022-04-01T00:00:00.000Z","authors":["fendy","hooopo"],"tags":["tidbcloud"],"image":"./import.png","description":"In this tutorial, we will provide you with a piece of sample data of all GitHub events occurring on January 1, 2022, and walk you through on how to use TiDB Cloud to analyze this data in 10 minutes.","keywords":["tutorial","TiDB Cloud Serverless Tier","Import massive data","column storage replica","tidb","top ranking","github","database","github archive","gitHub metrics"]},"prevItem":{"title":"SaaS Insight for Building a Real-time CRM Application","permalink":"/blog/saas-insight-for-building-a-real-time-crm-application"},"nextItem":{"title":"Data Preparation for Analytics","permalink":"/blog/how-it-works"}},"content":"[TiDB](https://docs.pingcap.com/tidb/stable/overview?utm_source=ossinsight&utm_medium=referral) is an open source distributed NewSQL database with horizontal scalability, high availability, and strong consistency. It can also deal with mixed OLTP and OLAP workloads at the same time by leveraging its hybrid transactional and analytical (HTAP) capability. \\n\\n**[TiDB Cloud](https://docs.pingcap.com/tidbcloud/public-preview?utm_source=ossinsight&utm_medium=referral) is a fully-managed Database-as-a-Service (DBaaS)** that brings everything great about TiDB to your cloud and lets you focus on your applications, not the complexities of your database. \\n\\nIn this tutorial, we will provide you with a piece of sample data of all GitHub events occurring on January 1, 2022, and walk you through on how to use TiDB Cloud to analyze this data in 10 minutes.  \\n\\n## Sign up for a TiDB Cloud account (Free)\\n\\n1. Click [here](https://tidbcloud.com/free-trial/?utm_source=ossinsight&utm_medium=community) to sign up for a TiDB Cloud account free of charge. \\n2. [Log in](https://tidbcloud.com/?utm_source=ossinsight&utm_medium=community) to your account.\\n\\n\x3c!--truncate--\x3e\\n\\n## Create a TiDB Cloud Serverless Tier cluster\\nOnce you register an account, you can create a cluster with TiDB Cloud Serverless Tier. \\n\\n:::info\\n A cluster is a database to store data. \\n:::\\n\\n1. Click **Get Started for Free** and start to create a cluster.\\n\\n![](./dev-tier.png)\\n\\n2. On the **Create a Cluster** page, set up your cluster name and root password.\\n3. Note that the cloud provider is AWS by default, and then **MUST** select the `US-West-2 (Oregon)` region to create the cluster.\\n4. The cluster tier is S1.dev by default.\\n5. Click **Submit**.\\nYour TiDB Cloud cluster will be created in approximately 1 to 3 minutes.\\n\\n\\n## Import data to your TiDB Cloud cluster\\n\\n### Import the data\\nOnce your cluster is ready, you can start to import the sample data to your cluster. \\n\\n:::info\\nWe have merged the create database/table in the SQL files, so you don\'t need to `create database/tables` by yourself.\\n\\nIf you want to know the table schema, you can check `desc gharchive_dev` later in the following step. \\n:::\\n\\n1. Click your cluster name in **Active Cluster** page to get into the detail page of your cluster.\\n2. Click the **Import** button on the **Active Clusters** page and then go to the **Data Import Task** page. \\n\\n![](./import.png)\\n\\n3. Copy the values below and paste to the blanks of **Bucket URL** and **Role-ARN** respectively on the **Data Import Task** page.\\n\\n**Bucket URL**:\\n```\\ns3://tidbcloud-samples/gharchive/\\n```\\n**Role-ARN**:\\n```\\narn:aws:iam::385595570414:role/import-sample-access\\n```\\n\\n4. Choose **US West (Oregon)** for your **Bucket region**;\\n5. Tick **TiDB Dumpling** for the **Data Format**. \\n6. Input your cluster password in the blank of **Password** on the **Target Database** section. \\n\\n![](./fill.png)\\n\\n7. After you fill in all the blanks on the **Data Import Task** page, click the **Import** button at the bottom of this page and wait for a few moments for the system to complete data importing. \\n\\n\\n### Use the web shell to check if data is ready\\nTiDB Cloud provides a web shell to connect the database online. \\n1. Click the **Exit** button after you successfully import the data into your cluster. \\n2. Click your cluster name in **Active Cluster** page to get into the detail page of your cluster.\\n3. Then, click the **Connect** button and the **Connect to TiDB** panel pops out. \\n4. Choose **Web SQL Shell** --\x3e **Open SQL Shell**. \\n5. Then input your cluster password as shown in the image below.\\n\\n![](./web-shell.png)\\n\\n\\n### Set column storage replica: TiFlash (Optional but could make SQL faster!) \\n\\n[TiFlash](https://docs.pingcap.com/tidb/stable/tiflash-overview?utm_source=ossinsight&utm_medium=referral) is the key component that makes TiDB / TiDB Cloud an HTAP database and capable of dealing with OLTP and OLAP workloads at the same time. \\n\\nHere, you can try the following SQL commands on TiDB Cloud to experience its real-time analytics with ease.\\n\\n1. Execute the SQL statements specified below \\n\\n```sql\\nuse gharchive_dev;\\nALTER TABLE github_events SET TIFLASH REPLICA 1;\\n```\\n\\n2. Setting a TiFlash replica will take you some time, so you can use the following SQL statements to check if the procedure is done or not. \\n\\n```sql\\nSELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = \'gharchive_dev\' and TABLE_NAME = \'github_events\';\\n```\\n\\nIf the results you get are the same as follows, then it means the procedure is done. \\n\\n```sql\\nmysql> SELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA = \'gharchive_dev\' and TABLE_NAME = \'github_events\';\\n+---------------+---------------+----------+---------------+-----------------+-----------+----------+\\n| TABLE_SCHEMA  | TABLE_NAME    | TABLE_ID | REPLICA_COUNT | LOCATION_LABELS | AVAILABLE | PROGRESS |\\n+---------------+---------------+----------+---------------+-----------------+-----------+----------+\\n| gharchive_dev | github_events |       68 |             1 |                 |         1 |        1 |\\n+---------------+---------------+----------+---------------+-----------------+-----------+----------+\\n1 row in set (0.27 sec)\\n\\nmysql>\\n```\\n\\n## Analysis!\\n\\nAfter you finish all the steps above, you can start the analytical process. \\n\\n:::tip\\nIf you want to know the table schema, you can use `show create table tbl_name` to get that information.\\n:::\\n\\nBecause you have imported the sample data of all GitHub events occurred on the first hour of 2022 (from 2022-01-01 00:00:00 to 2022-01-01 00:59:59), you can start to make any queries based on that data by using SQL commands. \\n\\n### How many events occurred in total?\\nExecute the following SQL statement to query the total number of events. \\n\\n```sql\\nSELECT count(*) FROM github_events;\\n```\\n\\n### Which repository gets the most stars?\\nExecute the following statements to query the most starred repository. \\n\\n```sql\\n  SELECT repo_name, count(*) AS events_count\\n    FROM github_events\\n   WHERE type = \'WatchEvent\' /* Yes, `WatchEvent` means star */\\nGROUP BY 1\\nORDER BY 2 DESC\\n   LIMIT 20;\\n```\\n\\n\\n## Mini Test\\nHere is a small test for you to practice how to use TiDB Cloud to conduct analytics. \\n\\n### Q: Who is the most active contributor except the robot accounts on the first hour of 2022?\\n\\n### Click for the answer. \u2b07\ufe0f\\n\\n<details><summary>Click me to show answer</summary>\\n\\n```sql\\n  SELECT actor_login, \\n         count(*) AS events_count\\n    FROM github_events\\n   WHERE actor_login NOT LIKE \'%bot%\'\\nGROUP BY 1\\nORDER BY 2 DESC \\n   LIMIT 20;\\n```\\n\\n</details>\\n\\n:::info\\n### \ud83c\udf1f Details in how OSS Insight works\\n\\nFind the reason [How we implement OSS Insight ?](/blog/why-we-choose-tidb-to-support-ossinsight).\\n\\nYou can find how we deal with massive github data in [Data Preparation for Analytics](/blog/how-it-works) as well!\\n:::"},{"id":"/how-it-works","metadata":{"permalink":"/blog/how-it-works","editUrl":"https://github.com/pingcap/ossinsight/edit/main/web/blog/how-it-works/index.md","source":"@site/blog/how-it-works/index.md","title":"Data Preparation for Analytics","description":"In this section, we will explain step by step how we process the massive data archived by GH Archive which up to 4.7 billion rows.","date":"2022-03-01T00:00:00.000Z","formattedDate":"March 1, 2022","tags":[{"label":"tidbcloud","permalink":"/blog/tags/tidbcloud"}],"readingTime":4.545,"hasTruncateMarker":true,"authors":[{"name":"hooopo","title":"Engineer of TiDB Community","url":"https://twitter.com/hooopo","imageURL":"https://github.com/hooopo.png","key":"hooopo"}],"frontMatter":{"title":"Data Preparation for Analytics","description":"In this section, we will explain step by step how we process the massive data archived by GH Archive which up to 4.7 billion rows.","image":"./thumbnail.png","date":"2022-03-01T00:00:00.000Z","authors":["hooopo"],"tags":["tidbcloud"]},"prevItem":{"title":"[Outdated] Use TiDB Cloud to Analyze GitHub Events in 10 Minutes","permalink":"/blog/try-it-yourself"}},"content":"## Data\\n\\nAll the data we use here on this website sources from [GH Archive](https://www.gharchive.org/), a non-profit project that records and archives all GitHub events data since 2011. The total data volume archived by GH Archive can be up to 4 billion rows. We download the `json file` on GH Archive and convert it into csv format via Script, and finally load it into the TiDB cluster in parallel through [TiDB-Lightning](https://docs.pingcap.com/tidb/stable/tidb-lightning-overview).\\n\\nIn this section, we will explain step by step how we conduct this process. \\n\\n1. Prepare the data in csv format for TiDB Lighting. \\n\\n\x3c!--truncate--\x3e\\n\\n```\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000000.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000001.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000002.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000003.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000004.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000005.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000006.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000007.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000008.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000009.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000010.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000011.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000012.csv\\n\u251c\u2500\u2500 gharchive_dev.github_events.000000000013.csv\\n```\\n\\n2. Configure the TiDB Lightning as follows.\\n\\n```\\ncat tidb-lightning.toml\\n[mydumper.csv]\\nseparator = \',\'\\ndelimiter = \'\\"\'\\nheader = true\\nnot-null = false\\nbackslash-escape = true\\ntrim-last-separator = false\\n\\n[tikv-importer]\\n backend = \\"local\\"\\n sorted-kv-dir = \\"/kvdir/\\"\\n\\ndisk-quota = \\"1.5TiB\\"\\n\\n[mydumper]\\ndata-source-dir = \\"/csv_dir/\\"\\nstrict-format = false\\nno-schema = true\\n\\n[tidb]\\nhost = \\"xxx\\"\\nport = 3306\\nuser = \\"github_events\\"\\npassword = \\"******\\"\\n\\n[lightning]\\ncheck-requirements = false\\nregion-concurrency = 32\\nmeta-schema-name = \\"gharchive_meta\\"\\n```\\n\\n3. Load the data into the TiDB cluster. \\n\\n```bash\\nnohup tidb-lightning -config ./tidb-lightning.toml > nohup.out\\n```\\n\\n4. Convert the unstructured `json file` provided by GH Archive into structured data. \\n\\n```\\ngharchive_dev> desc github_events;\\n+--------------------+--------------+------+-----+---------+-------+\\n| Field              | Type         | Null | Key | Default | Extra |\\n+--------------------+--------------+------+-----+---------+-------+\\n| id                 | bigint(20)   | YES  | MUL | <null>  |       |\\n| type               | varchar(255) | YES  | MUL | <null>  |       |\\n| created_at         | datetime     | YES  | MUL | <null>  |       |\\n| repo_id            | bigint(20)   | YES  | MUL | <null>  |       |\\n| repo_name          | varchar(255) | YES  | MUL | <null>  |       |\\n| actor_id           | bigint(20)   | YES  | MUL | <null>  |       |\\n| actor_login        | varchar(255) | YES  | MUL | <null>  |       |\\n| actor_location     | varchar(255) | YES  |     | <null>  |       |\\n| language           | varchar(255) | YES  | MUL | <null>  |       |\\n| additions          | bigint(20)   | YES  | MUL | <null>  |       |\\n| deletions          | bigint(20)   | YES  | MUL | <null>  |       |\\n| action             | varchar(255) | YES  | MUL | <null>  |       |\\n| number             | int(11)      | YES  |     | <null>  |       |\\n| commit_id          | varchar(255) | YES  | MUL | <null>  |       |\\n| comment_id         | bigint(20)   | YES  | MUL | <null>  |       |\\n| org_login          | varchar(255) | YES  | MUL | <null>  |       |\\n| org_id             | bigint(20)   | YES  | MUL | <null>  |       |\\n| state              | varchar(255) | YES  |     | <null>  |       |\\n| closed_at          | datetime     | YES  | MUL | <null>  |       |\\n| comments           | int(11)      | YES  | MUL | <null>  |       |\\n| pr_merged_at       | datetime     | YES  | MUL | <null>  |       |\\n| pr_merged          | tinyint(1)   | YES  |     | <null>  |       |\\n| pr_changed_files   | int(11)      | YES  | MUL | <null>  |       |\\n| pr_review_comments | int(11)      | YES  | MUL | <null>  |       |\\n| pr_or_issue_id     | bigint(20)   | YES  | MUL | <null>  |       |\\n| event_day          | date         | YES  | MUL | <null>  |       |\\n| event_month        | date         | YES  | MUL | <null>  |       |\\n| author_association | varchar(255) | YES  |     | <null>  |       |\\n| event_year         | int(11)      | YES  | MUL | <null>  |       |\\n| push_size          | int(11)      | YES  |     | <null>  |       |\\n| push_distinct_size | int(11)      | YES  |     | <null>  |       |\\n+--------------------+--------------+------+-----+---------+-------+\\n```\\n\\n5. With structured data at hand, we can start to make further analysis with TiDB Cloud. Execute SQL commands to generate analytical results. For example, you can execute SQL commands below to output the top 10 most starred JavaScript framework repos in 2021.\\n\\n```\\n  SELECT js.name, count(*) as stars \\n    FROM github_events \\n         JOIN js_framework_repos js ON js.id = github_events.repo_id \\n   WHERE type = \'WatchEvent\' and event_year = 2021 \\nGROUP BY 1 \\nORDER BY 2 DESC\\n   LIMIT 10;\\n+-------------------+-------+\\n| name              | stars |\\n+-------------------+-------+\\n| facebook/react    | 22830 |\\n| sveltejs/svelte   | 18573 |\\n| vuejs/vue         | 18015 |\\n| angular/angular   | 11037 |\\n| alpinejs/alpine   | 6993  |\\n| preactjs/preact   | 2965  |\\n| hotwired/stimulus | 1355  |\\n| marko-js/marko    | 1006  |\\n| neomjs/neo        | 826   |\\n| tastejs/todomvc   | 813   |\\n+-------------------+-------+\\n```\\n\\nWe have analyzed all the GitHub projects regarding databases, JavaScript frameworks, programming languages, web frameworks, and low-code development tools, and provided valuable insights in 2021, in real time, and custom insights. If the repository you care about is not included here, you\'re welcome to submit your PR [here](https://github.com/hooopo/gharchive/tree/main/meta/repos). If you want to gain more insights into other areas, you can try TiDB Cloud by yourselves with this [10-minute tutorial](/blog/try-it-yourself/). \\n\\nBelow are the areas of GitHub projects we have analyzed. \\n\\n```\\ngharchive_dev> show tables;\\n+-----------------------------+\\n| Tables_in_gharchive_dev     |\\n+-----------------------------+\\n| cn_repos                    |\\n| css_framework_repos         |\\n| db_repos                    |\\n| github_events               |\\n| js_framework_repos          |\\n| nocode_repos                |\\n| programming_language_repos  |\\n| static_site_generator_repos |\\n| web_framework_repos         |\\n+-----------------------------+\\n```\\n\\n:::info\\n### \ud83c\udf1f Details in how OSS Insight works\\n\\nGo to read [Use TiDB Cloud to Analyze GitHub Events in 10 Minutes](/blog/try-it-yourself) and use the [Serverless Tier](https://tidbcloud.com/free-trial/?utm_source=ossinsight&utm_medium=community) TiDB Cloud Cluster.\\n\\nYou can find the reason [How we implement OSS Insight ?](/blog/why-we-choose-tidb-to-support-ossinsight) as well!\\n:::"}]}')}}]);